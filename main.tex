% Document information
\def\myauthor{Esko Turunen and Santtu SÃ¶derholm}
\def\mycourse{Mathematical Logic -- Proof Theory}
\def\mytitle{Lecture Notes}
\def\myschool{Tampere University}
\def\implementation{Spring 2021}
% Document class
\documentclass[11pt,a4paper]{article}
\input{preamble.tex}
\input{trollface.tex}
% Document start
\begin{document}
\pagenumbering{gobble}
\input{titlepage.tex}
\tableofcontents
\pagebreak
\pagenumbering{arabic}

% -----  Main matter -----

\section{What is mathematics about?}

To answer the question set in the title of this chapter, \emph{proofs}.

\begin{example}[Proof by contradiction]
The infinite set of natural numbers \(\Nset = \set{1, 2, 3, \ldots}\) should already be familiar to you.
It is closed under addition \(+\) and multiplication \(\mult\).
In other words, if \(a, b\in\Nset\), then \(a + b \in\Nset\) and \(a\mult b\in\Nset\).
But what about division \(\div\)? We know that \(6 \div 2 = 3 \in\Nset\),
but \(3\div 6 = 1 / 2 \notin\Nset\).

It is known that some natural numbers are products of two \emph{other} natural numbers,
while others are not. For example, \(6 = 2 \mult 3\) and \(20 = 4 \mult 5\),
but
\[
2 = 2\mult 1,
\quad
3 = 3\mult 1,
\quad
5 = 5 \mult 1,
\quad
7 = 7 \mult 1,
\ldots\,.
\]
\end{example}
These numbers whose factors only consist of themselves and the number \(1\) are called \emph{prime numbers}
and denoted with \(\Pset\). How many prime numbers are there? We show that there are infinitely many via
\emph{proof by contradiction}.

Before we begin, let us analyze the products of prime numbers a bit more closely:
\begin{align*}
    2 \mult 3                   &= 6,   & 6 + 1     &= 7 \in\Pset \\
    2\mult 3 \mult 5            &= 30   & 30 + 1    &= 31 \in\Pset \\
    2 \mult 3 \mult 5 \mult 7   &= 210  & 210 + 1   &= 211\in\Pset\\
                                &\vdots &           &\vdots
\end{align*}
It seems like when the number \(1\) is added to any product of primes, the resulting number is prime.
We might also ask ourselves, whether the product of primes
\begin{equation*}\tag{hypothesis}
    \prod = 2 \mult 3 \mult 5 \mult\cdots\mult p_n \mult p_n+1 \in\Pset \,.
\end{equation*}
for all \(n\in\Nset\).

To prove this hypothesis, a natural seeming approach is to then make the \emph{contrapositive assumption},
that if \(p_i, p_n\in\Pset\), then
\begin{equation}
    \prod = 2\mult 3 \mult 5 \mult \cdots \mult p_i\mult\cdots \mult p_n \mult p_n + 1 = p_i\mult c \notin\Pset
\end{equation}
for some \(c\in\Nset\). But if this were the case, then
\begin{equation*}
    \frac\prod {p_i} = c = \frac{2 \mult 3 \mult 5 \mult \cdots \mult p_n + 1}{p_i} \notin\Nset\,.
\end{equation*}
This is in contradiction with our assumptions, which proves that there are infinitely many primes
(as the hypothessis provides us with a way of constructing them indefinitely).

\begin{example}[The derivative of a quadratic polynomial]
    See \url{https://www.youtube.com/watch?v=OhmexZXPVkE}.
\end{example}

\begin{example}[There exist non-rational real numbers]
    A rational number \(q\in\Qset\) is a real number,
    such that \(q = m\div n\) for some \(m,n\in\Zset\), where \(n\neq 0\).
    Real numbers \(r\in\Rset\) that are not rational are irrational,
    which can be stated bluntly as
    \begin{equation*}
        \nexists m, n \in \Zset, n\neq 0 : r = \frac m n : r \in \Rset - \Qset\,.
    \end{equation*}
    For example \(\sqrt 2\notin\Qset\).
\end{example}

\begin{theorem}\label{the:a to b in Q}
    There are \(a,b\notin\Qset\), so that \(a^b\in\Qset\).
\end{theorem}

\begin{proof}
    Let \(a, b = \sqrt 2\). If \(\sqrt 2 ^{\sqrt 2} \in\Qset\), then we are done.
    If this is not the case, let \(a = \sqrt2^{\sqrt 2}\) and \(b = \sqrt 2\).
    Then
    \begin{equation*}
        a^b = \arcs*{\sqrt2^{\sqrt 2}}^{\sqrt 2} = \sqrt 2 ^ 2 = 2 \in\Qset\,.
    \end{equation*}
    This concludes the proof.
\end{proof}

The proof of Theorem~\ref{the:a to b in Q} is an example of a \emph{non-constructive proof},
which are not allowed in \emph{non-intuitionistic} or \emph{constructive logic} \LJ.

Classical logic \LK{} only concerns itself with the notions of ''true'' and ''false''.
In other words, classical logic functions based on the following principle:
\begin{quote}
    ''Any well-formed mathematical object \(A\) is either true or false;
    if \(A\) is false, then not-\(A\) is true.''
\end{quote}
\emph{Tertium non datur}, ''\(A\) or not \(A\)'' is always true.
In intuitionistic logic \LJ, this is not the case.
It imposes the additional constraint that for an object \(A\)
to exist in the first place, one has to be able to \emph{construct}
such an \(A\).

All of logic is based on an abstract language, that we now study.

\section{\texorpdfstring{The language of classical logic \LK}{The language of classical logic LK}}

To be able to talk about any language, we must first define the set of symbols we are allowed to use.
This set is know as the \emph{alphabet}.

\begin{definition}[The alphabet of classical logic]%
    \label{def:classical alphabet}
    In the (formal) language of logic, valid strings consist of the following symbols:
    \begin{enumerate}
        \item\label{it:classical constants} Constants:
            \begin{enumerate}
                \item\label{it:classical constants individual}
                    Individual constants: \(k_j, j\in\Nset\cup\set 0\).
                \item\label{it:classical constants function}
                    Function constants with \(i\) argument places: \(f_j^i : i\in\Nset,j\in\Nset\cup\set0\).
                \item\label{it:classical constants predicates}
                    Predicate constants with \(i\) argument places: \(R_j^i : i, j\in\Nset\)
            \end{enumerate}
        \item\label{it:classical variables} Variables:
            \begin{enumerate}
                \item\label{it:classical variables free} Free variables \(a_j, j\in\Nset\cup\set0\),
                \item\label{it:classical variables bound} Bound variables \(x_j, j\in\Nset\cup\set0\)
            \end{enumerate}
        \item\label{it:classical logical symbols} The logical symbols \(\lnot\) (not), \(\land\) (and), \(\lor\) (or), \(\limplies\) (implies),
            \(\forall\) (for all) and \(\exists\). The first four are called \emph{propositional connectives}
            and the last two are so-called \emph{quantifiers}.
        \item\label{it:classical auciliary symbols} Auxiliary symbols: parentheses \((\) and \()\), and the comma \(,\).
    \end{enumerate}
\end{definition}

\begin{definition}[Term]%
    \label{def:classical term}
    The \emph{terms} or \emph{words} of the language of classical logic are defined recursively or inductively as follows:
    \begin{enumerate}
        \item\label{it:classical term 1}
            Every individual constant \(k_j\) is a term.
        \item\label{it:classical term 2}
            Every free variable \(a_j\) is a term.
        \item\label{it:classical term 3}
            If \(f^i\) is a function constant with \(i\) argument places and \(t_1,\ldots,t_i\) are terms,
            then \(f\arcs{t_1,\ldots,t_i}\) is a term.
        \item\label{it:classical term4}
            Terms are defined only by the items~\ref{it:classical term 1}--\ref{it:classical term 3} of this definition.
    \end{enumerate}
\end{definition}

\begin{definition}[Formulae and their outermost logical symbols]%
    \label{def:formulae and outermost logical symbols}
    If \(R^i\) is a predicate constant with \(i\) argument places and \(t_1,\ldots,t_i\) are terms,
    then \(R\arcs{t_1,\ldots,t_i}\) is an \emph{atomic formula}.
    \emph{Formulae} and their \emph{outermost logical symbols} are defined recursively as follows:
    \begin{enumerate}
        \item\label{it:formula 1}
            Every atomic formula is a formula. It has no outermost logical symbol.
        \item\label{it:formula 2}
            If \(A\) and \(B\) are fomulae, then \(\arcs{\lnot A}\), \(\arcs{A\land B}\),
            \(\arcs{A\lor B}\) and \(\arcs{A\limplies B}\) are formulae.
            Their outermost logical symbols are \(\lnot\), \(\land\),
            \(\lor\) and \(\limplies\), respectively.
        \item\label{it:formula 3}
            If \(A\) is a formula, \(a\) is a free variable and \(x\)
            a bound variable not occurring in \(A\),
            then \(\forall x A'\) and \(\exists x A'\) are formulae.
            Here \(A'\) refers to the expression obtained from \(A\),
            by replacing every occurrence of \(a\) with \(x\), wherever \(a\)
            occurs in \(A\).
            The outermost logical symbols of these formulae are \(\forall\) and \(\exists\), respectively.
        \item\label{it:formula 4}
            Formulae are only those expressions obtained by applying
            the items~\ref{it:formula 1}--\ref{it:formula 3}
            of this definition.
    \end{enumerate}
\end{definition}

\begin{definition}[The alphabet of formulae]\label{def:alphabet of formulae}
    The capital letters \(A_j, B_j, C_j, \ldots\) with or without the subindices
    \(j \in \Nset\cup\set0\) denote formulae. The Greek capital letters
    \(\Gamma_j, \Delta_j, \Pi_j,\ldots\) with or without the subindices
    \(j\in\Nset\cup\set0\) denote (finite) \emph{sequences} of formulae.
\end{definition}

For example, \(T: A_1, A_2(a), \exists x A_3(x), \forall y A_4(y)\) is a finite sequence,
as is \(\Delta: B_1, \exists x B_2(x)\).


\subsection{\texorpdfstring{Sequents, inferences and proofs in \LK}{Sequents, inferences and proofs in LK}}

\begin{definition}[Sequents, antecedents and succedents]%
    \label{def:sequent}
    If \(\Gamma\) and \(\Delta\) are sequences of formulae,
    then the expression \(\Gamma\seq\Delta\) is the \emph{sequent} of the two sequences.
    Here \(\Gamma\) is the \emph{antecedent} and \(\Delta\) the \emph{succedent}
    of the sequent.
\end{definition}

The natural meaning of \(A_1, \ldots,A_m\seq B_1,\ldots,B_n\) is that
\begin{center}
''If \(A_1\) and \(\cdots\) and \(A_m\), then \(B_1\) or \(\cdots\) or \(B_n\)''.
\end{center}
Note that the symbol \(\seq\) does not correspond to \(\limplies\).

\begin{definition}[Axioms]%
    \label{def:axiom}
    Sequents of the form \(A\seq A\) are called \emph{initial sequents} or \emph{axioms}.
\end{definition}

\begin{definition}[Contradiction and provability]%
    \label{def:contradiction and provability}
    A sequent without a succedent such as \(A_1, \ldots,A_m\seq\)
    is used to denote that \(A_1, \ldots,A_m\) yields a \emph{contradiction}.
    A sequent without an antecedent such as \(\seq B_1,\ldots,B_m\) means that
    \(B_1,\ldots,B_m\) is a \emph{provable}, or that \(B_1,\ldots,B_m\) \emph{holds}.
    A sequent with neither an antecedent or a succedent, as in \(\seq\),
    means that \emph{There is a contradiction}.
\end{definition}

\begin{definition}[Inferences, lower and upper sequents]%
    \label{def:inference}
    An \emph{inference} is an expression
    \begin{center}
    \begin{prooftree}
        \hypo{S_1}\infer1{S}
    \end{prooftree}
    \quad
    or
    \quad
    \begin{prooftree}
        \hypo{S_1}\hypo{S_2}\infer2{S}
    \end{prooftree}
    \end{center}
    where \(S_1\) and \(S_2\) are \emph{upper sequents} or \emph{predecessors} and \(S\)
    is a \emph{lower sequent} or \emph{successor}.
\end{definition}

The meaning of this notation is that if \(S_1\) and \(S_2\) are given,
\(S\) can be inferred from them. This inference could consist of multiple
individual inferences in sequence.

\begin{definition}[Proofs in \LK]\label{def:proof in LK}
    In classical logic \LK, a \emph{proof} \(P\)
    is a \emph{tree} of sequents, where
    \begin{enumerate}
        \item
            the leaves or \emph{premises} are axioms \(A\seq A\),
        \item
            the root or \emph{conclusion} of \(P\) has no lower sequents (or successors) and
        \item
            for every other sequent \(\Gamma_i\seq\Delta_i\in P\)
            there exists a sequent \(\Gamma_j\seq\Delta_j\in P\), so that
            \begin{equation*}
            \begin{prooftree}
                \hypo{\Gamma_i\seq\Delta_i}
                \infer1{\Gamma_j\seq\Delta_j}
            \end{prooftree}\,.
            \end{equation*}
    \end{enumerate}
\end{definition}

\begin{definition}[Inference rules in \LK]%
\label{def:inference rules in LK}
The following \emph{left} and \emph{right inference rules} are allowed in classical logic.
\begin{enumerate}
    \item\label{it:structural rules} Structural rules:
        \begin{enumerate}
            \item\label{it:weakening} Weakening:
                \begin{equation}
                    \tag{weakening:left}
                    \label{eq:weakening:left}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta}
                        \infer1{D, \Gamma\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{weakening:right}
                    \label{eq:weakening:right}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta}
                        \infer1{\Gamma\seq\Delta, D}
                    \end{prooftree}
                \end{equation}
                Here \(D\) is called the \emph{weakening formula}.
            \item\label{it:contraction} Contraction:
                \begin{equation}
                    \tag{contraction:left}
                    \label{eq:contraction:left}
                    \begin{prooftree}
                        \hypo{D, D, \Gamma\seq\Delta}
                        \infer1{D, \Gamma\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{contraction:right}
                    \label{eq:contraction:right}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, D, D}
                        \infer1{\Gamma\seq\Delta, D}
                    \end{prooftree}
                \end{equation}
            \item\label{it:exchange} Exchange:
                \begin{equation}
                    \tag{exchange:left}
                    \label{eq:exchange:left}
                    \begin{prooftree}
                        \hypo{\Gamma,C, D, \Pi\seq\Delta}
                        \infer1{\Gamma, D, C, \Pi\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{exchange:right}%
                    \label{eq:exchange:right}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, C, D, \Lambda}
                        \infer1{\Gamma\seq\Delta, D, C, \Lambda}
                    \end{prooftree}
                \end{equation}
            \item\label{it:cut} Cut:
                \begin{equation}
                    \tag{cut}
                    \label{eq:cut}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, D}
                        \hypo{D, \Pi\seq\Lambda}
                        \infer2{\Gamma, \Pi\seq\Delta, \Lambda}
                    \end{prooftree}
                \end{equation}
        \end{enumerate}
    \item\label{it:logical rules} Logical rules:
        \begin{enumerate}
            \item\label{it:negation} Negation:
                \begin{equation}
                    \tag{\(\lnot\):left}
                    \label{eq:lnot:left}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, D}
                        \infer1{\lnot D, \Gamma\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{\(\lnot\):right}
                    \label{eq:lnot:right}
                    \begin{prooftree}
                        \hypo{D, \Gamma\seq\Delta}
                        \infer1{\Gamma\seq\Delta, \lnot D}
                    \end{prooftree}
                \end{equation}
                Here \(D\) and \(\lnot D\) are the \emph{auxiliary} and \emph{principal} formulae
                of this inference, respectively.
            \item\label{it:conjugation} Conjugation:
                \begin{equation}
                    \tag{\(\land\):left}
                    \label{eq:land:left}
                    \begin{prooftree}
                        \hypo{C, \Gamma\seq\Delta}
                        \infer1{C\land D, \Gamma\seq\Delta}
                    \end{prooftree}
                    \quad\text{and}\quad
                    \begin{prooftree}
                        \hypo{D,\Gamma\seq\Delta}
                        \infer1{C\land D, \Gamma\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{\(\land\):right}
                    \label{eq:land:right}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, C}
                        \hypo{\Gamma\seq\Delta, D}
                        \infer2{\Gamma\seq\Delta, C\land D}
                    \end{prooftree}
                \end{equation}
                Here \(C\) and \(D\) are the \emph{auxiliary} formulae and \(C\land D\) the \emph{principal} formula
                of this inference.
            \item\label{it:disjunction} Disjunction:
                \begin{equation}
                    \tag{\(\lor\):left}
                    \label{eq:lor:left}
                    \begin{prooftree}
                        \hypo{C, \Gamma\seq\Delta}
                        \hypo{D, \Gamma\seq\Delta}
                        \infer2{C\lor D, \Gamma\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{\(\lor\):right}
                    \label{eq:lor:right}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, C}
                        \infer1{\Gamma\seq\Delta, C\lor D}
                    \end{prooftree}
                    \quad\text{and}\quad
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, D}
                        \infer1{\Gamma\seq\Delta, C\lor D}
                    \end{prooftree}
                \end{equation}
                Here \(C\) and \(D\) are the \emph{auxiliary} formulae and \(C\lor D\) the \emph{principal} formula
                of this inference.
            \item\label{implication} Implication:
                \begin{equation}
                    \tag{\(\limplies\):left}
                    \label{eq:limplies:left}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, C}
                        \hypo{D, \Pi\seq\Lambda}
                        \infer2{C\limplies D, \Gamma, \Pi\seq\Delta, \Lambda}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{\(\limplies\):right}
                    \label{eq:limplies:right}
                    \begin{prooftree}
                        \hypo{C, \Gamma\seq\Delta, D}
                        \infer1{\Gamma\seq\Delta, C\limplies D}
                    \end{prooftree}
                \end{equation}
                Here \(C\) and \(D\) are the \emph{auxiliary} formulae and \(C\limplies D\) the \emph{principal} formula
                of this inference.
            \item\label{it:universality} Universality:
                \begin{equation}
                    \tag{\(\forall\):left}
                    \label{eq:forall:left}
                    \begin{prooftree}
                        \hypo{F(t), \Gamma\seq\Delta}
                        \infer1{\forall x F(x), \Gamma\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{\(\forall\):right}
                    \label{eq:forall:right}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, F(a)}
                        \infer1{\Gamma\seq\Delta, \forall xF(x)}
                    \end{prooftree}
                \end{equation}
                Here \(t\) is an arbitrary term and \(a\) does not occur in the lower sequent.
                \(F(t)\) and \(F(a)\) are the \emph{auxiliary formulae}, whereas \(\forall xF(x)\)
                is the \emph{principal formula} of this inference.
            \item\label{it:existence} Existence:
                \begin{equation}
                    \tag{\(\exists\):left}
                    \label{eq:exists:left}
                    \begin{prooftree}
                        \hypo{F(a), \Gamma\seq\Delta}
                        \infer1{\exists{}x F(x), \Gamma\seq\Delta}
                    \end{prooftree}
                \end{equation}
                \begin{equation}
                    \tag{\(\exists\):right}
                    \label{eq:exists:right}
                    \begin{prooftree}
                        \hypo{\Gamma\seq\Delta, F(t)}
                        \infer1{\Gamma\seq\Delta, \exists{}xF(x)}
                    \end{prooftree}
                \end{equation}
                Again, here \(a\) does not occur in the lower sequent and \(t\) is an arbitrary term.
                \(F(t)\) and \(F(a)\) are the \emph{auxiliary formulae}, whereas \(\forall xF(x)\)
                is the \emph{principal formula} of this inference.
        \end{enumerate}
\end{enumerate}
\end{definition}

\paragraph{Note:}
Proof manipulation using inference rules always happens ''at the ends'' of sequents:
the first formula on the left of \(\seq\) and the last formula on the right of \(\seq\).

\begin{theorem}[Uniqueness of the axiom]%
    \label{the:uniqueness of the axiom}
    The sequent \(A\seq A\) is the only axiom.
\end{theorem}

\begin{proof}
    For any sequent \(\Gamma\seq\Lambda\), there exists a finite proof tree
    \begin{center}
    \begin{prooftree}
        \hypo{A\seq A}
        \infer1{\vdots}
        \hypo{B\seq B}
        \infer1{\vdots}
        \infer2{\Gamma_1\seq\Lambda_1}
        \hypo{C\seq C}
        \infer1{\vdots}
        \infer2{\vdots}
        \infer1{\Gamma\seq\Lambda}
    \end{prooftree}
    \end{center}
\end{proof}

If there is a tree whose root is \(\seq A\), then \(A\) is \LK-provable.
If a proof does not use the cut rule of definition~\ref{def:inference rules in LK}.\ref{it:cut},
then a proof is deemed \emph{cut free}.

\begin{definition}[Equivalence]\label{def:equivalence}
Two formulae \(A\) and \(B\) are \emph{equivalent},
if and only if
\begin{equation*}
\begin{prooftree}
    \hypo{\seq A\limplies B}
    \hypo{\seq B\limplies A}
    \infer2[\eqref{eq:land:right}]{\seq\arcs{A\limplies B}\land\arcs{B\limplies A}}
\end{prooftree}\,.
\end{equation*}
This is denoted with \(A\equiv B\).
\end{definition}

\subsection{Metalanguage versus object language}

In order to be able to discuss mathematics (or any other set of objects), we need to separate the ideas of
\emph{object language} and \emph{metalanguage}. Metalanguage is the natural language
that we use every day, whereas an object language consists of certain strings formed from
a certain alphabet, with a specific goal of describing a certain set of objects.
In this course, the object language is used to describe mathematical logic and
is formed from the definitions~\ref{def:classical alphabet}--\ref{def:inference}.
A hierarchical description of it is given in table~\ref{tab:language hierarchy}.

\begin{tabenv}{Object language hierarchy from highest to lowest. Objects higher in the hierarchy are constructed from objects that are lower in the hierarchy.}%
\label{tab:language hierarchy}
\small
\begin{tabular}{c|l|p{0.6\textwidth}}
    \toprule
    Object level& Object name & Examples\\
    \midrule
    6.  & Proofs    & {%
        \begin{prooftree}
            \hypo{A\seq{}A}
            \infer1{\vdots}
            \hypo{B\seq{}B}
            \infer1{\vdots}
            \infer2{\Gamma\seq\Delta}
        \end{prooftree}
        \qquad\qquad
        \begin{prooftree}
            \hypo{S_1}
            \ellipsis{}{}
            \hypo{S_2}
            \ellipsis{}{}
            \infer2{S_4}
            \hypo{S_3}
            \ellipsis{}{}
            \infer2{S}
        \end{prooftree}
    }\\
    \midrule
    5.  & Inferences & {
        \begin{prooftree}
            \hypo{S_1}
            \infer1{S}
        \end{prooftree}
        \qquad
        \begin{prooftree}
            \hypo{S_1}
            \hypo{S_2}
            \infer2{S}
        \end{prooftree}
    }\\
    \midrule
    4.  & Sequents  &   \(A_1,\ldots, A_m\seq B_1,\ldots,B_n\), \(\Gamma\seq\Delta\), \(\Pi\seq\Gamma\)\\
    \midrule
    3.  & Formulae  &   \(A, B, C,\ldots\), \(R\arcs{t_1,\ldots,t_n}\), \(a = b\), \(a + b = c\), \(0\mult a  = b \mult c\), \(a' = 0\),
                        \(\forall x\arcs{x + b = c}\), \(\exists x\arcs{x = a} \lor \lnot\exists z\arcs{z = b}\)\\
    \midrule
    2.  & Terms     &   \(0, \ldots\), \(a, b, c, \ldots\), \(0 + a\), \(a\mult b\), \(0'\),
i                       \(\arcs{a + b} \mult c\), \(t\), \(t_i\) \\
    \midrule
    1.  & Alphabet  &   \(0, \ldots\), \(a, b, c, \ldots\), \(x, y, z, \ldots\), \(+, \mult, ', \ldots\),
    \(\lnot, \land,\lor, \limplies, \forall, \exists, = \), \(R\arcs{,\ldots,}\), \((\), \()\)\\
    \bottomrule
\end{tabular}
\end{tabenv}

\subsection{\texorpdfstring{Examples of proofs in \LK}{Examples of proofs in LK}}

\begin{example}
    To prove \(\seq A \lor\lnot A\), we reason as follows:
\begin{equation*}
    \begin{prooftree}
        \hypo{A\seq A}
        \infer1[\eqref{eq:lnot:right}]{\seq A, \lnot A}
        \infer1[\eqref{eq:lor:right}]{\seq A, A\lor\lnot A}
        \infer1[\eqref{eq:exchange:right}]{\seq A\lor\lnot A, A}
        \infer1[\eqref{eq:lor:right}]{\seq A\lor\lnot A, A\lor\lnot A}
        \infer1[\eqref{eq:contraction:right}]{\seq A \lor\lnot A}
    \end{prooftree}
\end{equation*}
\end{example}

\begin{example}[Fully indicated axiom]\label{exa:fully indicated axiom}
    Fully indicated \(F(a)\) simply means that we may apply quantifier rules.
    To prove \(\seq\lnot\forall y\lnot F(y)\limplies\exists x F(x)\),
    we reason as follows:
\begin{equation*}
    \begin{prooftree}
        \hypo{F(a)\seq F(a)}
        \infer1[\eqref{eq:exists:right}]{F(a)\seq\exists x F(x)}
        \infer1[\eqref{eq:lnot:right}]{\seq\exists x F(x), \lnot F(a)}
        \infer1[\eqref{eq:forall:right}]{\seq\exists x F(x), \forall y \lnot F(y)}
        \infer1[\eqref{eq:lnot:left}]{\lnot\forall y\lnot F(y)\seq\exists x F(x)}
        \infer1[]{\seq\lnot\forall y\lnot F(y)\limplies\exists x F(x)}
    \end{prooftree}
\end{equation*}
\end{example}



\begin{example}[Exercise 2.5.1]\label{exa:2.5.1}
    To prove \(A\lor B\equiv \lnot\arcs{\lnot A\land\lnot B}\) we need to prove two things,
    according to the above note. First we show that
    \(\seq A\lor B\limplies\lnot\arcs{\lnot A\land\lnot B}\):

\begin{equation}\label{eq:equivalence example part 1}
    \begin{prooftree}
        % left branch
        \hypo{A\seq A}
        \infer1[\eqref{eq:lnot:left}]{\lnot A, A\seq}
        \infer1[\eqref{eq:land:left}]{\lnot A\land\lnot B, A\seq}
        \infer1[\eqref{eq:exchange:left}]{A, \lnot A\land\lnot B}
        % right branch
        \hypo{B\seq B}
        \infer1[\eqref{eq:lnot:left}]{\lnot B, B\seq}
        \infer1[\eqref{eq:land:left}]{\lnot A\land\lnot B, B\seq}
        \infer1[\eqref{eq:exchange:left}]{B, \lnot A\land\lnot B}
        % Trunk
        \infer2[\eqref{eq:lor:left}]{A\lor B, \lnot A \land\lnot B\seq}
        \infer1[\eqref{eq:exchange:left}]{\lnot A \land\lnot B, A\lor B\seq}
        \infer1[\eqref{eq:lnot:right}]{A\lor B \seq\lnot\arcs{\lnot A \land\lnot B}}
        \infer1[\eqref{eq:limplies:right}]{\seq A\lor B\limplies\lnot\arcs{\lnot A\land\lnot B}}
    \end{prooftree}
\end{equation}

Then we prove the statement \(\seq\lnot\arcs{\lnot A \land\lnot B} \limplies A\lor B\):

\begin{equation}\label{eq:equivalence example part 2}
    \begin{prooftree}
        \hypo{A\seq A}
        \infer1[\eqref{eq:lor:right}]{A\seq A\lor B}
        \infer1[\eqref{eq:lnot:right}]{\seq A\lor B, \lnot A}
        \hypo{B\seq B}
        \infer1[\eqref{eq:lor:right}]{B\seq A\lor B}
        \infer1[\eqref{eq:lnot:right}]{\seq A\lor B, \lnot B}
        \infer2[\eqref{eq:land:right}]{\seq A\lor B, \lnot A\land\lnot B}
        \infer1[\eqref{eq:lnot:left}]{\lnot\arcs{\lnot A \land\lnot B}\seq A\lor B}
        \infer1[\eqref{eq:limplies:right}]{\seq\lnot\arcs{\lnot A \land\lnot B}\limplies A\lor B}
    \end{prooftree}
\end{equation}

As the valid proofs~\ref{eq:equivalence example part 1} and \ref{eq:equivalence example part 2}
could be constructed, the claim holds. \qed
\end{example}

\begin{example}[Exercise 2.5.4]\label{exa:2.5.4}
    We wish to show that \(\lnot\forall y F(y)\equiv\exists x\lnot F(x)\).
    As per usual with equivalences, we need to do the proof in two parts.
    First we show that \(\seq\lnot\forall y F(y)\limplies\exists x\lnot F(x)\):

\begin{proof}
    \begin{equation}\label{exe:2.5.4:eq:1}
        \begin{prooftree}
            \hypo{F(a)\seq F(a)}
            \infer1[\eqref{eq:lnot:right}]{\seq F(a), \lnot F(a)}
            \infer1[\eqref{eq:exists:right}]{\seq F(a), \exists x\lnot F(x)}
            \infer1[\eqref{eq:exchange:right}]{\seq \exists x\lnot F(x), F(a)}
            \infer1[\eqref{eq:forall:right}]{\seq \exists x\lnot F(x), \forall y F(y)}
            \infer1[\eqref{eq:lnot:left}]{\lnot\forall y F(y)\seq \exists x\lnot F(x)}
            \infer1[\eqref{eq:limplies:right}]{\seq\lnot\forall y F(y)\limplies\exists x\lnot F(x)}
        \end{prooftree}
    \end{equation}
\end{proof}

    Then we prove the statement in the opposite direction,
    as in \(\seq\exists x\lnot F(x)\limplies\lnot\forall y F(y)\):

    \begin{proof}
        \begin{equation}\label{exe:2.5.4:eq:2}
            \begin{prooftree}
                \hypo{F(a)\seq F(a)}
                \infer1[\eqref{eq:forall:left}]{\forall y F(y)\seq F(a)}
                \infer1[\eqref{eq:lnot:right}]{\seq F(a), \lnot\forall y F(y)}
                \infer1[\eqref{eq:exchange:right}]{\seq\lnot\forall y F(y), F(a)}
                \infer1[\eqref{eq:lnot:left}]{\lnot F(a)\seq\lnot\forall yF(y)}
                \infer1[\eqref{eq:exists:left}]{\exists x\lnot F(x)\seq\lnot\forall yF(y)}
                \infer1[\eqref{eq:limplies:right}]{\seq\exists x\lnot F(x)\limplies\lnot\forall y F(y)}
            \end{prooftree}
        \end{equation}
    \end{proof}

    In light of proofs~\eqref{exe:2.5.4:eq:1} and \eqref{exe:2.5.4:eq:2}, the claim holds.
\end{example}

\begin{example}[Double negation in \LK]\label{exa:double negation in LK}
    We prove the law of double negation in \LK{} as follows:
\begin{equation*}
    \begin{prooftree}
        \hypo{A\seq A}
        \infer1[\eqref{eq:lnot:left}]{\lnot A, A\seq}
        \infer1[\eqref{eq:lnot:right}]{A\seq\lnot\lnot A}
        \infer1[\eqref{eq:limplies:right}]{\seq A\limplies\lnot\lnot A}
        \hypo{A\seq A}
        \infer1[\eqref{eq:lnot:right}]{\seq A, \lnot A}
        \infer1[\eqref{eq:lnot:left}]{\lnot\lnot A\seq A}
        \infer1[\eqref{eq:limplies:right}]{\seq\lnot\lnot A\limplies A}
        \infer2[\eqref{eq:land:right}]{\seq\arcs{A\limplies\lnot\lnot A}\land\arcs{\lnot\lnot A\limplies A}}
    \end{prooftree}
\end{equation*}
    Note that this also means that \(A\equiv A\).
    Note also that this proof is not possible in \LJ.
\end{example}

\begin{exercise}[2.7, A cut free proof]\label{exa:cut free proof}
    A cut free proof of \(\forall x A(x)\limplies B \seq \exists x \arcs{A(x)\limplies B}\),
    where \(A(a)\) and \(B\) are atomic and disjoint goes as follows:
    \begin{equation*}
        \begin{prooftree}
            \hypo{A(a)\seq A(a)}
            \infer1[\eqref{eq:weakening:right}]{A(a)\seq A(a), \forall x A(x)}
            \hypo{B\seq B}
            \infer2[\eqref{eq:limplies:left}]{A(a), \forall xA(x)\limplies B\seq A(a), B}
            \infer1[\eqref{eq:exchange:left}]{\forall xA(x)\limplies B, A(a)\seq, A(a), B}
            \infer1[\eqref{eq:limplies:right}]{\forall xA(x)\limplies B\seq A(a), A(a)\limplies B}
            \infer1[\eqref{eq:exists:right}]{\forall xA(x)\limplies B\seq A(a), \exists x\arcs{A(x)\limplies B}}
            \infer1[\eqref{eq:exchange:right}]{\forall xA(x)\limplies B\seq\exists x\arcs{A(x)\limplies B}, A(a)}
            \infer1[\eqref{eq:forall:right}]{\forall xA(x)\limplies B\seq\exists x\arcs{A(x)\limplies B}, \forall x A(x)}
            \hypo{B\seq B}
            \infer1[\eqref{eq:weakening:left}]{A(a), B\seq B}
            \infer1[\eqref{eq:limplies:right}]{B\seq A(a)\limplies B}
            \infer1[\eqref{eq:exists:right}]{B\seq\exists x\arcs{A(x)\limplies B}}
            \infer2[\eqref{eq:limplies:left}]{\forall x A(x)\limplies B, \forall x A(x)\limplies B \seq \exists x \arcs{A(x)\limplies B}, \exists x \arcs{A(x)\limplies B}}
            \infer1[\eqref{eq:contraction:left}]{\forall x A(x)\limplies B \seq \exists x \arcs{A(x)\limplies B}, \exists x \arcs{A(x)\limplies B}}
            \infer1[\eqref{eq:contraction:right}]{\forall x A(x)\limplies B \seq \exists x \arcs{A(x)\limplies B}}
            \infer1[\eqref{eq:limplies:right}]{\seq\arcs{\forall x A(x)\limplies B}\limplies\arcs{\exists x \arcs{A(x)\limplies B}}}
        \end{prooftree}
    \end{equation*}
\end{exercise}

\paragraph{Note:}
We also accept the inferences
\begin{equation*}
    \begin{prooftree}
        \hypo{\Gamma\seq\Delta}
        \infer1[\(\set{\eqref{eq:land:left},\eqref{eq:lor:left},\eqref{eq:limplies:left}}\)]{A\set{\land,\lor,\limplies } B, \Gamma\seq \Delta}
    \end{prooftree}
    \quad\text{and}\quad
    \begin{prooftree}
        \hypo{\Gamma\seq\Delta, A}
        \infer1[\eqref{eq:lor:right}]{\Gamma\seq\Delta, \arcs{B\land C}\lor A}
    \end{prooftree}
\end{equation*}

\begin{proposition}\label{prop:if provable, then atomic}
    If \(\Gamma\seq\Delta\) is provable without~\eqref{eq:cut},
    then we may assume that all of the related axioms are atomic,
    and that the proof is without cut.
\end{proposition}

\begin{proof}
    Omitted. See Takeuti's book~\cite[14-17]{Takeuti-1987} for the details.
\end{proof}

\begin{definition}[Alphabetical variants]\label{def:alphabetical variants}
    The formulae \(A\) and \(B\) are \emph{alphabetical variants}
    if they differ only in the names of their bound variables.
    This is denoted with \(A\varof{B}\). This is an equivalence relation.
\end{definition}

For example, it should be easily seen that
\begin{equation*}
    \exists x\arcs{f(x) = g(x)} \varof\exists y\arcs{f(y) = g(y)}\,.
\end{equation*}
It can be shown that if \(A\sim B\), then \(\seq\arcs{A\limplies B}\land\arcs{B\limplies A}\).
In other words, if \(A\varof B\) then \(A\equiv B\).



\subsection{Exercises}

\begin{exercise}[Exercise 2.5.2]\label{exe:2.5.2}
    Prove \(A\limplies B \equiv \lnot A\lor B\).
\end{exercise}

\begin{exercise}[Exercise 2.5.3]\label{exe:2.5.3}
    Prove \(\exists x F(x) \equiv\lnot\forall y\lnot F(y)\).
\end{exercise}
\begin{exercise}[Exercise 2.5.4]\label{exe:2.5.4}
    Prove \(\lnot\forall yF(y) \equiv\exists x\lnot F(x)\).
\end{exercise}
\begin{exercise}[Exercise 2.5.5]\label{exe:2.5.5}
    Prove \(\lnot\arcs{A\land B} \equiv \lnot A\lor\lnot B\).
\end{exercise}
\begin{exercise}[Exercise 2.6.1]\label{exe:2.6.1}
    Prove \(\exists x\arcs{A\limplies B(x)}\equiv A\limplies\exists xB(x)\).
\end{exercise}
\begin{exercise}[Exercise 2.6.2]\label{exe:2.6.2}
    Prove \(\exists x\arcs{A(x)\limplies B}\equiv\forall xA(x)\limplies B\),
    where \(B\) does not contain \(x\).
\end{exercise}
\begin{exercise}[Exercise 2.6.3]\label{exe:2.6.3}
    Prove \(\exists x\arcs{A(x)\limplies B(x)}\equiv\forall xA(x)\limplies\exists xB(x)\).
\end{exercise}
\begin{exercise}[Exercise 2.6.4]\label{exe:2.6.4}
    Prove \(\lnot A\limplies B\seq\lnot B\limplies A\)
\end{exercise}
\begin{exercise}[Exercise 2.6.5]\label{exe:2.6.5}
    Prove \(\lnot A\limplies\lnot B\seq B\limplies A\)
\end{exercise}


\section{\texorpdfstring{Intuitionistic predicate calculus \LJ}{Intuitionistic predicate calculus LJ}}

Intuitionistic logic \LJ{} is very similar to classical logic \LK,
except that in its inference rules, the succedents \(\Delta\) of upper sequents \(\Gamma\seq\Delta\)
may only contain \emph{at most} a single formula. For example, the inferences
\begin{equation*}
    \begin{prooftree}
        \hypo{\Gamma\seq D, D}
        \infer1[\eqref{eq:contraction:right}]{\Gamma\seq D}
    \end{prooftree}
    \quad\text{and}\quad
    \begin{prooftree}
        \hypo{\Gamma\seq C, D}
        \infer1[\eqref{eq:exchange:right}]{\Gamma\seq D, C}
    \end{prooftree}
\end{equation*}
are \emph{not} allowed in \LJ{}. This of course means, that \LJ{} is a true subset of \LK:
some proofs~\(P\) that are in \LK{} are not in \LJ{}.

\subsection{Examples}

\begin{example}[A proof in \LJ]\label{exa:a proof in LJ}
    \begin{equation*}
        \begin{prooftree}
            \hypo{A\seq A}
            \infer1[\eqref{eq:land:left}]{A\land\lnot A&\seq A}
            \infer1[\eqref{eq:lnot:left}]{\lnot A, A\land\lnot A&\seq}
            \infer1[\eqref{eq:land:left}]{A\land\lnot A, A\land\lnot A&\seq}
            \infer1[\eqref{eq:contraction:left}]{A\land\lnot A&\seq}
            \infer1[\eqref{eq:lnot:right}]{&\seq \lnot\arcs{A\land\lnot A}}
        \end{prooftree}
    \end{equation*}
\end{example}

\begin{example}[Another proof in \LJ]\label{exa:another proof in LJ}
    Prove that \(\lnot\exists xF(x)\seq\forall yF(y)\).
    \begin{equation*}
        \begin{prooftree}
            \hypo{F(a)&\seq F(a)}
            \infer1[\eqref{eq:exists:right}]{F(a)&\seq\exists xF(x)}
            \infer1[\eqref{eq:lnot:left}]{\lnot\exists xF(x), F(a)&\seq}
            \infer1[\eqref{eq:exchange:left}]{F(a), \lnot\exists xF(x)&\seq}
            \infer1[\eqref{eq:lnot:right}]{\lnot\exists xF(x)&\seq \lnot F(a)}
            \infer1[\eqref{eq:forall:right}]{\lnot\exists xF(x)&\seq \forall x\lnot F(x)}
            \infer1[\eqref{eq:limplies:right}]{&\seq \lnot\exists xF(x)\limplies\forall x\lnot F(x)}
        \end{prooftree}
    \end{equation*}
\end{example}

\subsection{Exercises}

\begin{exercise}[3.9.1]\label{exe:3.9.1}
    Prove in \LJ{:} \(\lnot A\lor B\seq A\limplies B\).
\end{exercise}
\begin{exercise}[3.9.2]\label{exe:3.9.2}
    Prove in \LJ{:} \(\exists xF(x)\seq\lnot\forall y\lnot F(y)\).
\end{exercise}
\begin{exercise}[3.9.3]\label{exe:3.9.3}
    Prove in \LJ{:} \(A\land B\seq A\).
\end{exercise}
\begin{exercise}[3.9.4]\label{exe:3.9.4}
    Prove in \LJ{:} \(A\seq A\lor B\).
\end{exercise}
\begin{exercise}[3.9.5]\label{exe:3.9.5}
    Prove in \LJ{:} \(\lnot A\lor\lnot B\seq \lnot\arcs{A\land B}\).
\end{exercise}
\begin{exercise}[3.9.6]\label{exe:3.9.6}
    Prove in \LJ{:} \(\lnot\arcs{A\lor B}\equiv\lnot A\land\lnot B\).
\end{exercise}
\begin{exercise}[3.9.7]\label{exe:3.9.7}
    Prove in \LJ{:} \(\arcs{A\lor C}\land\arcs{B\lor C} \equiv \arcs{A\land B}\lor C\).
\end{exercise}
\begin{exercise}[3.9.8]\label{exe:3.9.8}
    Prove in \LJ{:} \(\exists x\lnot F(x)\seq\lnot\forall xF(x)\).
\end{exercise}
\begin{exercise}[3.9.9]\label{exe:3.9.9}
    Prove in \LJ{:} \(\forall x\arcs{F(x)\land G(x)}\equiv\forall xF(x)\land\forall xG(x)\).
\end{exercise}
\begin{exercise}[3.9.10]\label{exe:3.9.10}
    Prove in \LJ{:} \(A\limplies\lnot B\seq B\limplies\lnot A\).
\end{exercise}
\begin{exercise}[3.9.11]\label{exe:3.9.11}
    Prove in \LJ{:} \(\exists x\arcs{A\limplies B(x)}\seq A\limplies\exists xB(x)\).
\end{exercise}
\begin{exercise}[3.9.12]\label{exe:3.9.12}
    Prove in \LJ{:} \(\exists x\arcs{A(x)\limplies B}\seq\forall xA(x)\limplies B\).
\end{exercise}
\begin{exercise}[3.9.13]\label{exe:3.9.13}
    Prove in \LJ{:} \(\exists x\arcs{A(x)\limplies B(x)}\seq\forall xA(x)\limplies\exists xB(x)\).
\end{exercise}
\begin{exercise}[3.10.1]\label{exe:3.10.1}
    Prove in \LJ{:} \(\lnot\lnot\arcs{A\limplies B}, A\seq\lnot\lnot B\).
\end{exercise}
\begin{exercise}[3.10.2]\label{exe:3.10.2}
    Prove in \LJ{:} \(\lnot\lnot B\limplies B, \lnot\lnot\arcs{A\limplies B}\seq A\limplies B\).
\end{exercise}
\begin{exercise}[3.10.3]\label{exe:3.10.3}
    Prove in \LJ{:} \(\lnot\lnot\lnot A\equiv\lnot A\).
\end{exercise}


\begin{example}[3.11]\label{exa:3.11}
    Let \(R\) be an atomic formula, and let \(J'\) be obtained from \LJ{} by adding the sequent~\(\lnot\lnot R\seq R\) as an axiom.
    Also let \(A\) be a formula which does not contain the symbols \(\lor\) or \(\exists\).
    Then \(\lnot\lnot A\seq A\) is \(J'\)-provable.

    \begin{proof}
        Let \(n\) be the number of logical symbols in \(A\).
        We prove the claim by structurally inducing on \(n\):
        \begin{enumerate}
            \item
                If \(n = 0\), then \(A = R\), as \(R\) is an atomic formula.
                By assumption \(\lnot\lnot R \seq R\), so the claim holds for the base case.
            \item
                Now assume that the inductive hypothesis \(\lnot\lnot A\seq A, \lnot\lnot B\seq B \in J''\) holds for the formulae \(A\) and \(B\),
                with at most \(n = k\) logical symbols. We add one additional allowed symbol to these formulae one at at time to close the induction:
                \begin{description}
                    \item[\(\lnot\)]
                        By exercise~\ref{exe:3.10.3}, \(\lnot\lnot\arcs{\lnot A}\seq\lnot A\) can be proven.
                    \item[\(\limplies\)]
                        We show that the claim \(\lnot\lnot\arcs{A\limplies B} \seq A\limplies B\) can be proven.
                        In the proof, IH refers to the inductive hypothesis:
                        \begin{equation*}
                            \begin{prooftree}
                                \hypo{B\seq B}
                                \ellipsis{\IH}{\lnot\lnot B\seq B}
                                \infer1[\eqref{eq:limplies:right}]{\seq\lnot\lnot B\limplies B}
                                \hypo{A\seq A}
                                \hypo{B\seq B}
                                \infer2{}
                                \ellipsis{(Exercise~\ref{exe:3.10.2})}{\lnot\lnot\arcs{A\limplies B} \seq A\limplies B}
                                \infer2[\eqref{eq:cut}]{\lnot\lnot\arcs{A\limplies B} \seq A\limplies B}
                            \end{prooftree}
                        \end{equation*}
                    \item[\(\land\)]
                        Again, we show that the claim \(\lnot\lnot\arcs{A\land B} \seq A\land B\) can be proven.
                        Also again, IH refers to the inductive hypothesis:
                        \tiny
                        \begin{equation*}
                            \begin{prooftree}
                                \hypo{A&\seq A}
                                \infer1[\eqref{eq:land:left}]{A\land B&\seq A}
                                \infer1[\eqref{eq:lnot:left}]{\lnot A, A\land B&\seq}
                                \infer1[\eqref{eq:exchange:left}]{A\land B,\lnot A&\seq}
                                \infer1[\eqref{eq:lnot:right}]{\lnot A&\seq\lnot\arcs{ A\land B}}
                                \infer1[\eqref{eq:lnot:left}]{\lnot\lnot\arcs{A\land B}, \lnot A&\seq}
                                \infer1[\eqref{eq:exchange:left}]{\lnot A, \lnot\lnot\arcs{A\land B}&\seq}
                                \infer1[\eqref{eq:lnot:right}]{\lnot\lnot\arcs{A\land B}&\seq\lnot\lnot A}
                                \hypo{A\seq A}
                                \ellipsis{\IH}{\lnot\lnot A\seq A}
                                \infer2[\eqref{eq:cut}]{\lnot\lnot\arcs{A\land B}\seq A}
                                \hypo{B&\seq B}
                                \infer1[\eqref{eq:land:left}]{A\land B&\seq B}
                                \infer1[\eqref{eq:lnot:left}]{\lnot B, A\land B&\seq}
                                \infer1[\eqref{eq:exchange:left}]{A\land B,\lnot B&\seq}
                                \infer1[\eqref{eq:lnot:right}]{\lnot B&\seq\lnot\arcs{ A\land B}}
                                \infer1[\eqref{eq:lnot:left}]{\lnot\lnot\arcs{A\land B}, \lnot B&\seq}
                                \infer1[\eqref{eq:exchange:left}]{\lnot B, \lnot\lnot\arcs{A\land B}&\seq}
                                \infer1[\eqref{eq:lnot:right}]{\lnot\lnot\arcs{A\land B}&\seq\lnot\lnot B}
                                \hypo{B\seq B}
                                \ellipsis{\IH}{\lnot\lnot B\seq B}
                                \infer2[\eqref{eq:cut}]{\lnot\lnot\arcs{A\land B}\seq B}
                                \infer2[\eqref{eq:land:right}]{\lnot\lnot\arcs{A\land B} \seq A\land B}
                            \end{prooftree}
                        \end{equation*}
                        \normalsize
                    \item[\(\forall\)]
                        Lastly, we show that the claim \(\lnot\lnot\forall xA(x) \seq \forall xA(x)\) is a theorem:
                        \footnotesize
                        \begin{equation*}
                            \begin{prooftree}
                                \hypo{A(a)\seq A(a)}
                                \infer1[\eqref{eq:forall:left}]{\forall xA(x)&\seq A(a)}
                                \infer1[\eqref{eq:lnot:left}]{\lnot A(a),\forall xA(x)&\seq}
                                \infer1[\eqref{eq:exchange:left}]{\forall xA(x),\lnot A(a)&\seq}
                                \infer1[\eqref{eq:lnot:right}]{\lnot A(a)&\seq\lnot\forall xA(x)}
                                \infer1[\eqref{eq:lnot:left}]{\lnot\lnot\forall xA(x), \lnot A(a)&\seq}
                                \infer1[\eqref{eq:exchange:left}]{\lnot A(a), \lnot\lnot\forall xA(x)&\seq}
                                \infer1[\eqref{eq:lnot:right}]{\lnot\lnot\forall xA(x)&\seq \lnot\lnot A(a)}
                                \hypo{A(a)\seq A(a)}
                                \ellipsis{\IH}{\lnot\lnot A(a)\seq A(a)}
                                \infer2[\eqref{eq:cut}]{\lnot\lnot\forall xA(x) \seq A(a)}
                                \infer1[\eqref{eq:forall:right}]{\lnot\lnot\forall xA(x) \seq \forall xA(x)}
                            \end{prooftree}
                        \end{equation*}
                        \normalsize
                \end{description}
        \end{enumerate}
        By the inductive principle, we are then done.
    \end{proof}
\end{example}

\subsection{\texorpdfstring{The relation between \LK{} and \LJ}{The relation between LK and LJ}}

Our last goal in discussing what the specific connection between \LK{} and \LJ{} is.
For this purpose we declare the notational definitions in definition~\ref{def:starred formulae in LK}.

\begin{definition}[Starred formula variants in \LK]\label{def:starred formulae in LK}
    Table~\ref{tab:starred variants in LK} defines a recursive mapping,
    between formulae \(A\) and their starred variants \(A^\ast\).

    \begin{tabenv}{Mapping between formulae \(A\) and their transformations \(A^\ast\).}%
        \label{tab:starred variants in LK}
        \begin{tabular}{C|C}
            \toprule
            \text{Formula } A & \text{Transformation } A^\ast \\
            \midrule
            \text{atomic } A & \lnot\lnot A \\
            \lnot B & \lnot\arcs{B^\ast} \\
            B\land C & B^\ast\land C^\ast \\
            B\lor C & \lnot\arcs{\lnot B^\ast\land\lnot C^\ast} \\
            \forall xB(x) & \forall xB^\ast(x) \\
            \exists xB(x) & \lnot\forall x\lnot B^\ast(x) \\
            B\limplies C & B^\ast\limplies C^\ast \\
            \bottomrule
        \end{tabular}
    \end{tabenv}
\end{definition}

With definition~\ref{def:starred formulae in LK} in place, we can proceed to make the propositions that follow.

\begin{proposition}[Claim 1]\label{prop:claim 1 in LK vs LJ}
    \(A\equiv A^\ast\) for all \(A\) in \LK.
\end{proposition}

\begin{proof}
    Just like with example~\ref{exa:3.11}, the proof can be achieved via induction over the number of logical symbols in \(A\).
    \begin{enumerate}
        \item
            For the base case, we observe that by the double negation law proved in example~\ref{exa:double negation in LK},
            \(A\equiv\lnot\lnot A = A^\ast\).
        \item
            For the induction hypothesis \IH, we assume that for the formulae \(B\) and \(C\),
            \(B\equiv B^\ast\) and \(C\equiv C^\ast\). To close the hypothesis,
            we add one allowed logical symbol at a time to \(A\) formed from \(B\) and/or \(C\),
            as necessary:
            \begin{description}
                \item[\lnot]
                    If \(A = \lnot B\), then \(A^\ast = \lnot\lnot\lnot B\),
                    and \(A\equiv A^\ast\) by exercise~\ref{exe:3.10.3}.
                \item[\land]
                    If \(A = B\land C\), then \(A^\ast = B^\ast\land C^\ast\) and we argue as follows:
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{B\seq B}
                            \ellipsis{\IH}{B\seq B^\ast}
                            \infer1{B\land C\seq B^\ast}
                            \hypo{C\seq C}
                            \ellipsis{\IH}{C\seq C^\ast}
                            \infer1{B\land C\seq C^\ast}
                            \infer2{B\land C \seq B^\ast\land C^\ast}
                            \hypo{B\seq B}
                            \ellipsis{\IH}{B^\ast\seq B}
                            \infer1{B^\ast\land C^\ast\seq B}
                            \hypo{C\seq C}
                            \ellipsis{\IH}{C^\ast\seq C}
                            \infer1{B^\ast\land C^\ast\seq C}
                            \infer2{B^\ast\land C^\ast \seq B\land C}
                            \infer2{B\land C \equiv B^\ast\land C^\ast}
                        \end{prooftree}
                    \end{equation*}
                \pagebreak
                \item[\lor]
                    \begin{exercise}[3.12.1 part iii]\label{exe:3.12.1.iii}
                        This is left as an exercise. Show that \(A \equiv A^\ast\), when \(A=B\lor C\).
                    \end{exercise}
                \item[\forall]
                    If \(A = \forall xB(x)\), then \(A^\ast = \forall xB^\ast(x)\).
                    Now we can argue as follows:
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{B(a\seq B(a))}
                            \ellipsis{\IH}{B(a)\seq B^\ast(a)}
                            \infer1[\eqref{eq:forall:left}]{\forall xB(x)\seq B^\ast(a)}
                            \infer1[\eqref{eq:forall:right}]{\forall xB(x)\seq\forall xB^\ast(x)}
                            \hypo{B(a\seq B(a))}
                            \ellipsis{identical to left branch}{\forall xB^\ast(x)\seq\forall xB(x)}
                            \infer2{\forall xB^\ast(x)\equiv\forall xB(x)}
                        \end{prooftree}
                    \end{equation*}
                \item[\limplies]
                    If \(A = B\limplies C\), then \(A^\ast = B^\ast\limplies C^\ast\).
                    The argument is then
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{B\seq B}
                            \ellipsis{\IH}{B^\ast\seq B}
                            \hypo{C\seq C}
                            \ellipsis{\IH}{C\seq C^\ast}
                            \infer[left label=\eqref{eq:limplies:left}]2{B\limplies C, B^\ast\seq C^\ast}
                            \infer[left label=\eqref{eq:exchange:left}]1{B^\ast, B\limplies C\seq C^\ast}
                            \infer[left label=\eqref{eq:limplies:right}]1{B\limplies C\seq B^\ast\limplies C^\ast}
                            \hypo{B\seq B}
                            \ellipsis{\IH}{B\seq B^\ast}
                            \hypo{C\seq C}
                            \ellipsis{\IH}{C^\ast\seq C}
                            \infer[left label=\eqref{eq:limplies:left}]2{B^\ast\limplies C^\ast, B\seq C}
                            \infer[left label=\eqref{eq:exchange:left}]1{B, B^\ast\limplies C^\ast\seq C}
                            \infer[left label=\eqref{eq:limplies:right}]1{B^\ast\limplies C^\ast\seq B\limplies C}
                            \infer2{B^\ast\limplies C^\ast\equiv B\limplies C}
                        \end{prooftree}
                    \end{equation*}
                \item[\exists]
                    \begin{exercise}[3.12.1 part vi]\label{exe:3.12.1.vi}
                        This is left as an exercise. Show that if \(A = \exists xB(x)\), then \(A\equiv A^\ast\).
                    \end{exercise}
            \end{description}
    \end{enumerate}
    By the inductive principle, we are then done.
\end{proof}

\begin{proposition}[Claim 2]\label{prop:claim 2 in LK vs LJ}
    If \(S\) is the sequent \(A_1,\ldots,A_m\seq B_1,\ldots,B_n\),
    then we may define the sequent
    \(S'\coloneqq A_1^\ast,\ldots,A_m^\ast,\lnot B_1^\ast,\ldots,\lnot B^\ast_n\seq\).
    Now \(S\) is \LK-provable, if and only if \(S'\) is \LK-provable.
\end{proposition}

\begin{proof}[Sketch of proof]
    We start by proving that if \(S\) is provable (meaning we can use it as a premise of a proof),
    then \(S'\) is also provable:
    \tiny

    \begin{equation*}
        \begin{prooftree}
            \hypo{A_2^\ast\seq\lnot\lnot A_2^\ast}
            \hypo{A_1^\ast\seq\lnot\lnot A_1^\ast}
            % Tallest branch
            \hypo{\overbrace{A_1,\ldots,A_m\seq B_1,\ldots,B_n}^{S}}
            \hypo{B_n\seq B_n^\ast}
            \infer2[\eqref{eq:cut}]{A_1,\ldots,A_m\seq B_1,\ldots,B_{n-1}, B_n^\ast}
            \infer1[\eqref{eq:exchange:right}]{A_1,\ldots,A_m\seq B_1,\ldots,B_n^\ast, B_{n-1}}
            \hypo{B_{n-1}\seq B_{n-1}^\ast}
            \infer2[\eqref{eq:cut}]{A_1,\ldots,A_m\seq B_1,\ldots,B_n^\ast, B_{n-1}^\ast}
            \infer[double]1[\eqref{eq:exchange:right}s and \eqref{eq:cut}s]{A_1,\ldots,A_m\seq B_n^\ast,\ldots,B_1^\ast}
            \infer[double]1[\eqref{eq:lnot:left}s and \eqref{eq:exchange:left}s]{A_1,\ldots,A_m, \lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq}
            \infer[double]1[\eqref{eq:lnot:right}s and \eqref{eq:exchange:right}s]{\lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq\lnot A_m,\ldots,\lnot A_1}
            \hypo{\lnot A_1\seq \lnot A^\ast_1}
            \infer[left label=\eqref{eq:cut} and \eqref{eq:exchange:right}]2{\lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq\lnot A_m,\ldots,\lnot A_1^\ast,\lnot A_2}
            \hypo{\lnot A_2\seq\lnot A_2^\ast}
            \infer[double,left label=\eqref{eq:cut}s and \eqref{eq:exchange:right}s]2{\lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq\lnot A_1^\ast,\ldots,\lnot A_m^\ast}
            \infer[double,left label=\eqref{eq:lnot:right}s and \eqref{eq:exchange:left}s]1{\lnot\lnot A_1^\ast,\ldots,\lnot\lnot A_m^\ast, \lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq}
            \infer2[\eqref{eq:cut}]{\lnot\lnot A_2^\ast,\ldots,\lnot\lnot A_m^\ast, \lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq}
            \infer[double]2[multiple \eqref{eq:cut}s]{A_1^\ast,\ldots,A_m^\ast, \lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq}
        \end{prooftree}
    \end{equation*}
    \normalsize
    On the last line, \(A_1^\ast,\ldots,A_m^\ast, \lnot B_n^\ast,\ldots,\lnot B_1^\ast\seq = S'\).
    The proof in the other direction is performed in a similar manner.
\end{proof}

\begin{proposition}[Claim 3]\label{prop:claim 3 in LK vs LJ}
    \(A^\ast\equiv\lnot\lnot A^\ast\) in \LJ.
\end{proposition}

\begin{proof}
    In \LJ{}, the proof
    \begin{equation*}
        \begin{prooftree}
            \hypo{A\seq A}
            \infer1{\lnot A, A\seq}
            \infer1{A\seq\lnot\lnot A}
        \end{prooftree}
    \end{equation*}
    is valid for all formulae \(A\). This means it must also be true for \(A^\ast\seq\lnot\lnot A^\ast\) as well.

    By example~\ref{exa:3.11}, \(\lnot\lnot A\seq A\) in \LJ{'}.
    Also, by exercise~\ref{exe:3.10.3} we have \(\lnot\lnot\lnot\arcs{\lnot R}\equiv\lnot\lnot R\) in \LJ{},
    for all atomic formula \(R\).
    As the formula \(A^\ast\) does not contain the symbols \(\lor\) or \(\exists\) by assumption,
    we can conclude that \(\lnot\lnot A^\ast\seq A\).
    Therefore \(A^\ast\equiv \lnot\lnot A^\ast\) for all \(A\) in \LJ{}.
\end{proof}

\begin{proposition}[Claim 4]\label{prop:claim 4 in LK vs LJ}
    If the sequent \(S\) of proposition~\ref{prop:claim 2 in LK vs LJ} is provable in \LK,
    then the sequent \(S'\) defined in the same proposition is provable in \LJ.
\end{proposition}

\begin{proof}[A sketch of a proof]
    Let \(n\) refer to the length of a proof, as in the number of inferences of a proof in \LK{}.
    We induce on this \(n\):
    \begin{enumerate}
        \item
            For the base case \(n=0\), all proofs \(P = A\seq A\) in \LK{}.
            Then in \LJ{} we have \(A^\ast\seq A^\ast\) and
            \begin{equation*}
                \begin{prooftree}
                    \hypo{A^\ast\seq A^\ast}
                    \infer1[\eqref{eq:lnot:left}]{\lnot A^\ast, A^\ast\seq}
                    \infer1[\eqref{eq:exchange:left}]{A^\ast, \lnot A^\ast\seq}
                \end{prooftree}
            \end{equation*}
        \item
            For the inductive hypothesis \IH, let the claim in \LK{} hold for a proof of length \(n \leq p\).
            Note that based on the number of inference rules in definition~\ref{def:inference rules in LK},
            the number of \emph{subcases} of \(n = p+1\) is \(21\). Let us cover some of them:
            \begin{enumerate}
                \item
                    In \LK{} we have
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{A_1,\ldots,A_k\seq B_1,\ldots,B_l}
                            \infer1[\eqref{eq:weakening:left}]{A, A_1,\ldots,A_k\seq B_1,\ldots B_1,\ldots,B_l}
                        \end{prooftree}
                    \end{equation*}
                    whereas in \LJ{} this means that
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{A_1^\ast,\ldots, A_k^\ast, \lnot B_1^\ast,\ldots,\lnot B_l^\ast\seq}
                            \infer1[\eqref{eq:weakening:left}]{A^\ast, A_1,\ldots,A_k, \lnot B_1^\ast,\ldots,\lnot B_l^\ast\seq}
                        \end{prooftree}
                    \end{equation*}
                    by the inductive hypothesis.
                \item
                    In \LK{} we have
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{A_1,\ldots, A_i,A_j,\ldots,A_k\seq B_1,\ldots,B_l}
                            \infer1[\eqref{eq:exchange:left}]{A_1,\ldots, A_j,A_i,\ldots,A_k\seq B_1,\ldots,B_l}
                        \end{prooftree}
                    \end{equation*}
                    whereas in \LJ{} this means that
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{A_1^\ast,\ldots, A_i^\ast,A_j^\ast,\ldots,A_k^\ast, \lnot B_1^\ast,\ldots,\lnot B_l^\ast\seq}
                            \infer1[\eqref{eq:exchange:left}]{A_1^\ast,\ldots, A_j^\ast,A_i^\ast,\ldots,A_k^\ast, \lnot B_1^\ast,\ldots,\lnot B_l^\ast\seq},
                        \end{prooftree}\,,
                    \end{equation*}
                    again by the inductive hypothesis.
                \item
                    In \LK{}, by the rule~\eqref{eq:cut} (the \(p+1\)st inference):
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{A_1,\ldots,A_i\seq B_1,\ldots,B_j, D}
                            \hypo{D, A_{i+1},\ldots,A_k\seq B_{j+1},\ldots,B_l, D}
                            \infer2{A_1,\ldots,A_k\seq B_1,\ldots,B_l}
                        \end{prooftree}
                    \end{equation*}
                    Then by the inductive hypothesis the inference
                    \scriptsize
                    \begin{equation*}
                        \begin{prooftree}
                            \hypo{A_1^\ast,\ldots,A_i^\ast, \lnot B_1^\ast,\ldots,\lnot B_j^\ast,\lnot D^\ast\seq}
                            \infer[double]1[\eqref{eq:exchange:left}]{\lnot D^\ast, A_1^\ast,\ldots,A_i^\ast, \lnot B_1^\ast,\ldots,\lnot B_j^\ast\seq}
                            \infer1[\eqref{eq:lnot:right}]{A_1^\ast,\ldots,A_i^\ast, \lnot B_1^\ast,\ldots,\lnot B_j^\ast\seq\lnot\lnot D^\ast}
                            \hypo{\text{proposition}~\ref{prop:claim 3 in LK vs LJ}}
                            \ellipsis{}{\lnot\lnot D^\ast\seq D^\ast}
                            \infer2[\eqref{eq:cut}]{A_1^\ast,\ldots,A_i^\ast, \lnot B_1^\ast,\ldots,\lnot B_j^\ast\seq D^\ast}
                            \hypo{\IH}
                            \ellipsis{}{D^\ast, A_{i+1}^\ast,\ldots,A_k^\ast, \lnot B_{j+1}^\ast,\ldots,\lnot B_l^\ast\seq}
                            \infer[left label=\eqref{eq:cut}]2{A_1^\ast,\ldots,A_i^\ast, \lnot B_1^\ast,\ldots,\lnot B_j^\ast,A_{i+1}^\ast,\ldots,A_k^\ast, \lnot B_{j+1}^\ast,\ldots,\lnot B_l^\ast\seq}
                            \infer[rule style=double]1[\eqref{eq:exchange:left}]{A_1^\ast,\ldots,A_k^\ast, \lnot B_1^\ast,\ldots,\lnot B_l^\ast\seq}
                        \end{prooftree}
                    \end{equation*}
                    \normalsize
                \pagebreak
                \item
                    \begin{exercise}[3.12.4 part vii]\label{exe:3.12.4.vii}
                    This is left as an exercise.
                    If \(S\) is the sequent \(A_1,\ldots,A_k\seq B_1,\ldots,B_l\),
                    then we may define the sequent
                    \(S'\coloneqq A_1^\ast, \ldots, A_k^\ast,\linebreak
                    \lnot B_1^\ast, \ldots, \lnot B^\ast_l\seq\).
                    Show that if the sequent \(S\) is provable in \LK,
                    then the sequent \(S'\) is provable in \LJ{}
                    for the case, where the \(\arcs{p+1}\)st inference is
                    by~\eqref{eq:lnot:right} in \LK{}.
                    \end{exercise}
            \end{enumerate}
    \end{enumerate}

    The rest of the applications of inference rules needed in the inductive step
    are omitted in these notes, but may be done as an exercise.
    By the inductive principle, we can now conclude that if the sequent
    \(A_1,\ldots,A_k\seq B_1,\ldots,B_l\) is in \LK{},
    then the sequent \(A_1^\ast,\ldots,A_k^\ast, \lnot B_1^\ast,\ldots,\lnot B_l^\ast\seq\) is in \LJ{}.
\end{proof}

The converse of proposition~\ref{prop:claim 4 in LK vs LJ} also holds,
but the proof is just as long and will therefore be omitted.
Lastly, we cover the most important fact related to this section.

\begin{theorem}[Connection between \LK{} and \LJ]\label{the:connection between LK and LJ}
    For all formulae \(A\), \(\seq A\) in \LK{}, if and only if \(\seq A^\ast\) in \LJ{}.
\end{theorem}

\begin{proof}
    A particular instance of exercise~\ref{exe:3.12.4.vii} is the following:
    if \(\seq A\) in \LJ{}, then \(\lnot A^\ast\seq\) in LJ{}.
    Therefore
    \begin{equation*}
        \begin{prooftree}
            \hypo{\lnot A^\ast\seq}
            \infer1[\eqref{eq:lnot:right}]{\seq\lnot\lnot A^\ast}
            \hypo{A\seq A}
            \ellipsis{Proposition~\ref{prop:claim 3 in LK vs LJ}}{A^\ast\seq A}
            \infer2[\eqref{eq:cut}]{\seq A^\ast}
        \end{prooftree}
    \end{equation*}

    Conversely, if \(\seq A^\ast\) in \LJ{} and by proposition~\ref{prop:claim 1 in LK vs LJ} we know that \(A\equiv A^\ast\) in \LK{},
    we also have \(A^\ast\seq A\) in \LK{}. Thus
    \begin{equation*}
        \begin{prooftree}
            \hypo{\seq A^\ast}
            \hypo{A^\ast\seq A}
            \infer2[\eqref{eq:cut}]{\seq A}
        \end{prooftree}\,.
        \qedhere
    \end{equation*}
\end{proof}



\section{\texorpdfstring{Axiom systems based on \LK}{Axiom systems based on LK}}

Let \(\sset A = \set{A_1,\ldots,A_n}\) or \(\sset A = \set{A_1,A_2,\ldots}\)
be respectively finite or infinite sets of formulae.
An \emph{axiom system} in classical logic \LK, denoted \(\LKsys[\sset A]\),
is the set of theorems provable from the axioms formed from the formulae in \(\sset A\),
using the inference rules of definition~\ref{def:inference rules in LK}.
Such an axiom is either a sequent \mbox{\(A\seq A\)},
or a single formula \(A_i\), for all formulae \(A,A_i\in\sset A\).

\begin{definition}[Consistency]\label{def:consistency}
    An axiom system \(\LKsys\) is \emph{consistent}, if the empty sequent \(\seq\)
    is \emph{not} provable in \(\LKsys\). The system \(\LKsys\) is \emph{inconsistent}
    if the empty sequent \emph{can} be derived in it.
\end{definition}

In other words, consistent axiom systems cannot produce contradictions,
as per definition~\ref{def:contradiction and provability}.
The following proposition concerns equivalencies in inconsistent systems.

\begin{proposition}[Equivalencies in inconsistent systems]%
\label{prop:equivalencies in inconsistent systems}
The following are equivalent statements:
\begin{enumerate}[label={(\alph*)}]
    \item\label{it:equivalencies in inconsistent systems 1}
        \(\LKsys\) is inconsistent,
    \item\label{it:equivalencies in inconsistent systems 2}
        \(\seq A\) is provable for all formulae \(A\) and
    \item\label{it:equivalencies in inconsistent systems 3}
        for some \(A\), both \(\seq A\) and \(\seq \lnot A\) are provable in \(\LKsys\).
\end{enumerate}
\end{proposition}

\begin{proof}
\item[\ref{it:equivalencies in inconsistent systems 1}\(\implies\)\ref{it:equivalencies in inconsistent systems 2}]
    If the empty sequent \(\seq\) is provable, then it can be used as a leaf of a proof.
    Therefore the following argument can be made:
    \begin{prooftree}
        \hypo{\seq}
        \infer1[\eqref{eq:weakening:right}]{\seq A}
    \end{prooftree}\,.
\item[\ref{it:equivalencies in inconsistent systems 2}\(\implies\)\ref{it:equivalencies in inconsistent systems 3}]
    If \(\seq A\) is provable for all \(A\),
    we can set \(A = B\) and \(A = \lnot C\) for some \(B\) and \(C\),
    so that \(\seq B\) and \(\seq\lnot C\) are provable.
\item[\ref{it:equivalencies in inconsistent systems 3}\(\implies\)\ref{it:equivalencies in inconsistent systems 1}]
    By assumption, there exists an \(A\), so that
    \begin{equation*}
        \begin{prooftree}
            \hypo{\seq\lnot A}
            \hypo{\seq A}
            \infer1[\eqref{eq:lnot:left}]{\lnot A\seq}
            \infer2[\eqref{eq:cut}]{\seq}
        \end{prooftree}
    \end{equation*}
    Therefore the system \(\LKsys\) in which this proof was made is inconsistent
    by definition~\ref{def:consistency}.
\end{proof}

\section{\texorpdfstring{The Cut-elimination theorem in \LK}{The Cut-elimination theorem in LK}}

This theorem is also known as \emph{Gentzen's Haubtsatz}.
In short, the theorem goes as follows: If a theorem is provable,
then it is provable without~\eqref{eq:cut}.
We need multiple assisting results,
before this can be proven,
and some of the details will be omitted for brevity.

\begin{lemma}[The mix rule, Lemma 5.2]\label{lem:mix rule}
    Let \(\Gamma\), \(\Delta\), \(\Delta^\ast\), \(\Pi\), \(\Pi^\ast\) and \(\Lambda\) be sequence formulae
    and \(A\) a single formula, such that \(A\in\Delta\), \(A\in\Pi\),
    \(A\notin\Delta^\ast\) and \(A\notin\Pi^\ast\). Then the rule~\eqref{eq:cut}
    can be replaced by the rule
    \begin{equation}\label{eq:mix}\tag{mix}
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta}
            \hypo{\Pi\seq\Lambda}
            \infer2[\(\eqref{eq:mix}:A\)]{\Gamma,\Pi^\ast\seq\Delta^\ast\Lambda}
        \end{prooftree}\,.
    \end{equation}
\end{lemma}

\begin{proof}
    Let the number of instances of \(A\) in the sequence
    formulae \(\Delta\) and \(\Pi\) be \(k\) and \(l\),
    respectively. Also assume that the rule~\eqref{eq:cut}
    is usable in the following manner:
    \begin{equation*}
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta, A}
            \hypo{A, \Pi\seq\Lambda}
            \infer2[\eqref{eq:cut}]{\Gamma,\Pi\seq\Delta,\Lambda}
        \end{prooftree}\,.
    \end{equation*}
    The same result can be obtained by applying the \eqref{eq:mix} rule with respect to \(A\):
    \begin{equation*}
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta, A}
            \hypo{A, \Pi\seq\Lambda}
            \infer2[\(\eqref{eq:mix}:A\)]{\Gamma,\Pi^\ast\seq\Delta^\ast,\Lambda}
            \infer[rule style=double]1[\(l\times\eqref{eq:weakening:left}\) and \eqref{eq:exchange:left}]{
                \Gamma,\Pi\seq\Delta^\ast,\Lambda
            }
            \infer[rule style=double]1[\(k\times\eqref{eq:weakening:right}\) and \eqref{eq:exchange:right}]{
                \Gamma,\Pi\seq\Delta,\Lambda
            }
        \end{prooftree}
    \end{equation*}

    Then assume that the \eqref{eq:mix} rule with respect to \(A\) can be used in the proof
    \begin{equation*}
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta}
            \hypo{\Pi\seq\Lambda}
            \infer2[\(\eqref{eq:mix}:A\)]{\Gamma,\Pi^\ast\seq\Delta^\ast,\Lambda}
        \end{prooftree} \,.
    \end{equation*}
    If we now assume that \(l\geq k\), the \eqref{eq:cut} rule can be used to prove the same theorem:
    \begin{equation*}
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta}
            \infer[rule style=double]1[\eqref{eq:exchange:right}]{\Gamma\seq\Delta^\ast, A,\ldots, A}
            \infer[rule style=double]1[\eqref{eq:contraction:right}]{\Gamma\seq\Delta^\ast, A}
            \hypo{\Pi\seq\Lambda}
            \infer[rule style=double,left label=\eqref{eq:exchange:left}]1{A,\ldots,A,\Pi^\ast\seq\Lambda}
            \infer[rule style=double,left label=\eqref{eq:contraction:left}]1{A,\Pi^\ast\seq\Lambda}
            \infer2[\eqref{eq:cut}]{\Gamma,\Pi^\ast\seq\Delta^\ast,\Lambda}
        \end{prooftree}\,.
    \end{equation*}
    Therefore the rules \eqref{eq:cut} and \eqref{eq:mix} are equivalent in \LK.
\end{proof}

\begin{lemma}[Lemma 5.4]\label{lem:5.4}
Assume that the set of proofs \(\LK^\ast\) is obtained from
the set \LK{} by replacing the \eqref{eq:cut} rule by
the \eqref{eq:mix} rule. Assume that \(S\) is a sequent,
whose proof~\(P\in\LK^\ast\), such that the last inference rule of \(P\)
is the only instance of \eqref{eq:mix} in \(P\).
Then \(P\in\LK\).
\end{lemma}

\begin{proof}
    By double induction. TODO.
\end{proof}

\begin{theorem}[Theorem 5.3]\label{the:5.3}
    If a sequent \(S\) is provable by using the \eqref{eq:mix} rule,
    then it is also provable without it.
\end{theorem}

\begin{proof}[An idea of the proof]
    Let \(P\) be a proof of \(S\).
    Now investigate some branch of \(P\),
    where and instance of the \eqref{eq:mix} rule appears.
    By lemma~\ref{lem:5.4}, this branch can be replaced by
    a \eqref{eq:mix}-free proof \(Q\), ending in \(S\).
    We continue applying this procedure to all
    \eqref{eq:mix}-containing branches of \(P\),
    until no branches with instances of the \eqref{eq:mix} rule
    exist in \(P\). This concludes the proof.
\end{proof}

Together with Lemmas~\ref{lem:mix rule} and \ref{lem:5.4},
Theorem~\ref{the:5.3} proves Gentzen's Haubsatz.

\begin{theorem}[Theorem 5.5]\label{the:5.5}
    The cut-elimination theorem also holds in \LJ.
\end{theorem}

\section{\texorpdfstring{Consequences of Cut-elimination -- Consistency of \LK{} an \LJ}{Consequences of Cut-elimination -- Consistency of LK{} an LJ}}

To begin discussion on this topic, we need to have an idea
of what the word \emph{subformula} means. Thankfully,
the idea is not very difficult and is illustrated by
the following examples:
\begin{itemize}
    \item
        The subformulae of \(\exists xF(x)\) are the formula itself,
        \(F(a)\), and the subformulae of \(F(a)\).
    \item
        The subformulae of \(C\land D\) are \(C\land D\), \(C\) and \(D\),
        and the subformulae of \(C\) and \(D\).
\end{itemize}
In other words, subformulae of a formula \(A\) are the formulae that are used
to construct \(A\), including \(A\) itself.

If we think of the inferences
\begin{equation*}
    \begin{prooftree}
        \hypo{T'\seq\Delta'}
        \hypo{T''\seq\Delta''}
        \infer2{\Gamma\seq\Delta}
    \end{prooftree}
    \quad\text{and}\quad
    \begin{prooftree}
        \hypo{T'\seq\Delta'}
        \infer1{\Gamma\seq\Delta}
    \end{prooftree}\,,
\end{equation*}
we notice that the upper sequents are always composed of subformulae
of the lower sequents, but not conversely. We then have the following result.

\begin{theorem}[Subformula property]\label{the:subformula property}
    If \(P\) is a proof of the sequent \(\Gamma\seq\Delta\),
    then \(P\) contains only formulae that are subformulae of
    the sequence formulae \(\Gamma\) and \(\Delta\), but not conversely.
\end{theorem}

\begin{proof}
    Omitted.
\end{proof}

Now we can establish the following central result.

\begin{theorem}\label{eq:consistency of LK and LJ}
    The sets \LK{} and \LJ{} are consistent,
    as per definition~\ref{def:consistency}.
\end{theorem}

\begin{proof}
    We proceed by the contrapositive principle and
    assume to the contrary, so that the empty sequent \(\seq\)
    is provable in \LK{} or \LJ{}. Then by the previous results
    it can be proven without the \eqref{eq:cut} rule,
    and therefore the supposed proof can only contain empty sequents
    because of theorem~\ref{the:subformula property}.
    But for a proof to be a proof, it has to start with an
    axiom, which is of the form \(A\seq A\),
    which is not an empty sequent. This is a contradiction,
    so the claim must be true.
\end{proof}

\begin{theorem}\label{the:6.3}
    In a \eqref{eq:cut}-free proof \(P\) of \(\Gamma\seq\Delta\),
    all formulae are subformulae of \(\Gamma\) and \(\Delta\).
\end{theorem}

\begin{proof}[A sketch of a proof]
    By induction on the number of inferences in \(P\),
    denoted by \(n\). In the base case, \(n=0\)
    and we only have axioms \(A\seq A\) and the claim holds.

    As the inductive hypothesis, we assume that the claim holds
    for \(n=k\) inferences. In the inductive step, we simply
    add the known inference rules one at a time and check that
    the claim still holds.
\end{proof}

\section{\texorpdfstring{Completeness of \LK}{Completeness of LK}}

We would like to show the following in \LK:
for any formula \(A\), if \(\seq A\) is provable,
then A is a \emph{valid} formula.
This leads to the \emph{soundness} and eventually \emph{completeness} of \LK.
To establish what these concepts mean, we give the following
(rather long) sequence of definitions.

\begin{definition}[Structure of language]\label{def:structure of language}
    Let \(L\) be a language as described in table~\ref{tab:language hierarchy}.
    The \emph{structure} of such a language is an ordered pair \(\tuple{D,\phi}\),
    where \(D\) is a non-empty set and \(\phi\) a map from the constants of \(L\)
    such that
    \begin{enumerate}
        \item
            if \(k\) is an individual constant, then \(\phi(k)\in D\),
        \item
            if \(f\) is a function constant of \(n\) arguments,
            then \(\phi(f): D^n\to D\) and
        \item
            if \(R\) is a predicate constant of \(n\) arguments,
            then \(\phi(R)\subseteq D^n\).
    \end{enumerate}
\end{definition}

\begin{definition}[Interpretation of language]\label{def:interpretation of language}
    An \emph{interpretation} \(\interp\) of a language \(L\) is an ordered pair \(\tuple{S,\phi_0}\),
    where \(S\) is a structure \(\tuple{D,\phi}\) and \(\phi_0\)
    is a mapping from the variables of \(L\) to \(D\).
    The map \(\phi_0\) is called an \emph{assignment} from \(D\)
    and is defined as follows:
    \begin{enumerate}
        \item
            \(\phi_0\arcs{a}\in D\) for all free variables \(a\) and
        \item
            \(\phi_0\arcs{x}\in D\) for all bound variables \(x\).
    \end{enumerate}
\end{definition}

\begin{definition}[Extension of \(\phi\)]\label{def:extension of structure map}
    We define \(\phi\arcs{t}\) in a structure \(S = \tuple{D,\phi}\)
    for every \emph{semi-term} \(t\) inductively
    as follows:
    \begin{enumerate}
    \item
        \(\phi\arcs{a} = \phi_0\arcs{a}\) and \(\phi\arcs{x} = \phi_0\arcs{x}\)
        for all free variables \(a\) and bound variables \(x\).
    \item
        In addition,
        if \(f\) is a function constant and \(t\) is a semi-term for which \(\phi\)
        is already defined, then \(\phi\arcs{f\arcs{t}} = \arcs{\phi f}\arcs{\phi t}\).
    \end{enumerate}
\end{definition}

\begin{definition}[Formula-satisfying interpretation]\label{def:formula satisfying interpretation}
    An interpretation \(\interp = \tuple{S,\phi_0} = \tuple{\tuple{D,\phi},\phi_0}\)
    \emph{satisfies} a formula \(A\), if the following are true:
    \begin{enumerate}
        \item
            If \(R\) is a predicate constant of \(n\) arguments
            and \(t_1,\ldots,t_n\) are semi-terms, then \(\interp\)
            satisfies \(R\arcs{t_1,\ldots,t_n}\), if and only if
            \(\tuple{\phi t_1,\ldots,\phi t_n}\in\phi R \subseteq D^n\).
        \item
            The interpretation \(\interp\) satisfies \(\lnot A\),
            if and only if it does \emph{not} satisfy \(A\).
        \item
            \(\interp\) satisfies \(A\land B\), if and only if it satisfies
            both \(A\) and \(B\).
        \item
            The formula \(A\lor B\)
            is satisfied by \(\interp\), if and only if it
            satisfies either \(A\) or \(B\).
        \item
            The implication \(A\limplies B\) is satisfied by \(\interp\),
            if and only if \(A\) is not satisfied,
            or \(B\) is satisfied.
        \item
            The interpretation \(\interp = \tuple{\tuple{D,\phi},\phi_0}\)
            satisfies \(\forall xB\arcs{x}\), if and only if for \emph{every} \(\phi_0'\)
            such that \(\phi_0'(x) = \phi_0(x)\) almost everywhere,
            the interpretation \(\interp'=\tuple{\tuple{D,\phi},\phi_0'}\) satisfies \(B\).
        \item
            The interpretation \(\interp = \tuple{\tuple{D,\phi},\phi_0}\)
            satisfies \(\exists xB\arcs{x}\), if and only if for \emph{some} \(\phi_0'\)
            such that \(\phi_0'(x) = \phi_0(x)\) almost everywhere,
            the interpretation \(\interp'=\tuple{\tuple{D,\phi},\phi_0'}\) satisfies \(B\).
    \end{enumerate}
    If \(\interp = \tuple{\tuple{D,\phi},\phi_0}\) satisfies a formula \(A\),
    \(A\) is said to be satisfied in \(\tuple{D,\phi}\) by the assignment \(\phi_0\).
\end{definition}

Note that in the above definition, \emph{almost everywhere} means that there might
exist some \(a\) for which \(\phi_0'(a)\neq\phi_0(a)\).

\begin{definition}[Valid formula]\label{def:valid formula}
    A formula \(A\) is said to be \emph{valid in} the structure \(\tuple{D,\phi}\),
    if and only if for every \(\phi_0\),
    the interpretation \(\tuple{\tuple{D,\phi},\phi_0}\)
    satisfies \(A\). The formula \(A\) is simply \emph{valid}, if
    it is valid in every structure.
\end{definition}

\begin{definition}[Satisfied and valid sequents]%
\label{def:satisfied and valid sequents}
A sequent \(\Gamma\seq\Delta\) is \emph{satisfied in} the structure
\(\tuple{D,\phi}\) \emph{by} an interpretation \(\interp\),
if and only if either some formula in \(\Gamma\) is \emph{not}
satisfied by \(\interp\), or some formula in \(\Delta\) \emph{is}
satisfied by \(\interp\). A sequent is \emph{valid}, if and only if
it is satisfied in every interpretation.
\end{definition}

\begin{definition}[Model and Counter-Model]%
\label{def:model and counter-model}
A structure \(S\) is called a \emph{model} of an axiom system
\(\Gamma\), if every sentence of \(\Gamma\) is valid in \(S\).
On the other hand, \(S\) is a \emph{counter-model} of \(\Gamma\),
if there is a sentence of \(\Gamma\) that is not valid in \(S\).
\end{definition}

The definitions needed in proving the completeness of \LK{},
namely theorems~\ref{the:provability implies validity}
and \ref{the:validity implies provability},
are now mostly in place. In essence, the completeness of \LK{}
means that a formula \(A\) is provable,
if and only if it is valid.

\begin{theorem}[Provability implies validity]\label{the:provability implies validity}
    If a formula \(A\) is provable, the it is valid.
\end{theorem}

\begin{proof}
    The proof is by structural induction on the number inferences
    in the proof of \(\Gamma\seq\Delta\), denoted by \(n\).
    If \(n=0\) a proof only consists of axioms of the form \(A\seq A\),
    where the antecedent \(A\) is never satisfied in the interpretation
    \(\interp\), whereas the succedent \(A\) always is. Therefore the
    sequent \(A\seq A\) is always satisfied in all \(\interp\) and is then valid.

    We now make the induction hypothesis \IH, that if the number of inferences
    \(n\leq k\) in the proofs of the sequents \(\Gamma\seq\Delta\) and \(\Pi\seq\Lambda\),
    then both of them are valid. In the inductive step, we add each of the inference
    rules in definition \ref{def:inference rules in LK} to the proof one at a time
    (except \eqref{eq:cut}), and check that validity is preserved.

    \paragraph{Structural rules.}
    These follow directly from the definition of validity.
    In the inferences
    \begin{equation*}
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta}
            \infer1[\eqref{eq:weakening:left}]{A, \Gamma\seq\Delta}
        \end{prooftree}
        \quad\text{and}\quad
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta}
            \infer1[\eqref{eq:weakening:right}]{\Gamma\seq\Delta, A}
        \end{prooftree}\,,
    \end{equation*}
    the sequence \(\Gamma\) contains at least one \emph{invalid} formula \(B\),
    whereas \(\Delta\) contains at least one \emph{valid} formula \(B\) by the inductive hypothesis.
    The other two types of non-\eqref{eq:cut} structural inferences
    \begin{equation*}
        \begin{prooftree}
            \hypo{A,A,\Gamma\seq\Delta}
            \infer1[\eqref{eq:contraction:left}]{A, \Gamma\seq\Delta}
        \end{prooftree}
        \quad\text{and}\quad
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta,A,A}
            \infer1[\eqref{eq:contraction:right}]{\Gamma\seq\Delta, A}
        \end{prooftree}\,,
    \end{equation*}
    and
    \begin{equation*}
        \begin{prooftree}
            \hypo{C,D,\Gamma\seq\Delta}
            \infer1[\eqref{eq:exchange:left}]{D,C,\Gamma\seq\Delta}
        \end{prooftree}
        \quad\text{and}\quad
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta,C,D}
            \infer1[\eqref{eq:exchange:right}]{\Gamma\seq\Delta, D,C}
        \end{prooftree}\,,
    \end{equation*}
    also preserve validity by the same logic.

    \paragraph{Logical rules.}
    We start with the rules
    \begin{equation*}
        \begin{prooftree}
            \hypo{\Gamma\seq\Delta,A}
            \infer1[\eqref{eq:lnot:left}]{\lnot A, \Gamma\seq\Delta}
        \end{prooftree}
        \quad\text{and}\quad
        \begin{prooftree}
            \hypo{A, \Gamma\seq\Delta}
            \infer1[\eqref{eq:lnot:right}]{\Gamma\seq\Delta, \lnot A}
        \end{prooftree}\,.
    \end{equation*}
    Given an interpretation \(\interp\),
    if the satisfied formula is in \(\Delta\) or the unsatisfied
    one in \(\Gamma\), then there is nothing to prove.
    Otherwise, if \(A\) is the satisfied formula,
    then \(\lnot A\) is not satisfied by definition,
    meaning \(\lnot A\) must contain a formula \(C\) that is not satisfied.
    This implies that the sequent \(\lnot A,\Gamma\seq\Delta\) is satisfied by definition.
    The proof of the sequent \(\Gamma\seq\Delta,\lnot A\) being satisfied
    in the inference \eqref{eq:lnot:right} is entirely symmetrical to this.

    \begin{exercise}[Exercise 8.2.1]\label{exe:8.2.1}
        Prove the inductive step in the inferences~\eqref{eq:land:left},
        \eqref{eq:land:right}, \eqref{eq:lor:left}, \eqref{eq:lor:right},
        \eqref{eq:limplies:left} and \eqref{eq:limplies:right}.
    \end{exercise}

    \begin{exercise}[Exercise 8.2.2]\label{exe:8.2.2}
        Prove the inductive step in the inferences~\eqref{eq:forall:left},
        \eqref{eq:forall:right}, \eqref{eq:exists:left} and \eqref{eq:exists:right}.
    \end{exercise}

    With all of the inference rules covered,
    the induction is closed and the proof is now complete.
\end{proof}

To prove the converse, that the validity of the sequent \(\seq A\)
implies the provability of \(\seq A\), we will need on moredefinition:
the concept of \emph{reduction trees}.

\begin{definition}[Reduction tree]\label{def:reduction tree}
    Let \(\Gamma\seq\Delta\) be a sequent.
    The \emph{reduction tree} \(T\arcs{\Gamma\seq\Delta}\)
    for this sequent is constructed
    programmatically as follows:
    \begin{enumerate}
        \item\label{it:reduction tree init}
            Place the sequent \(\Gamma\seq\Delta\) at the root of the tree.
        \item\label{it:reduction tree loop}
            The branches of the tree are defined by looping over the current
            leaves:
            \begin{enumerate}
                \item\label{it:reduction tree finished}
                    If every topmost sequent contains a same formula
                    in both its antecedent and succedent,
                    then halt the program.
                \item\label{it:reduction tree unfinished}
                    Else iterate over the leaves of the current branches
                    and perform one of the following \emph{reductions} or additions,
                    depending on which logical symbols are the outermost symbols in \(\Pi\) or \(\Lambda\),
                    when \(\Pi\seq\Lambda\) is the sequent in each leaf during each iteration:
                    \begin{enumerate}
                        \item\label{it:reduction tree lnot left}
                            Let \(\lnot A_1,\ldots,\lnot A_n\in\Pi\) with
                            \(\lnot\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\lnot\):left}
                                    \label{eq:reduction:lnot:left}
                                    \hypo{\Pi\seq\Lambda, A_1,\ldots,A_n}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree lnot right}
                            Let \(\lnot A_1,\ldots,\lnot A_n\in\Lambda\) with
                            \(\lnot\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\lnot\):right}
                                    \label{eq:reduction:lnot:right}
                                    \hypo{A_1,\ldots,A_n,\Pi\seq\Lambda}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree land left}
                            Let \(A_1\land B_1,\ldots,A_n\land B_n\in\Pi\) with
                            \(\land\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\land\):left}
                                    \label{eq:reduction:land:left}
                                    \hypo{A_1, B_1,\ldots,A_n, B_n,\Pi\seq\Lambda}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree land right}
                            Let \(A_1\land B_1,\ldots,A_n\land B_n\in\Lambda\) with
                            \(\land\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\land\):right}
                                    \label{eq:reduction:land:right}
                                    \hypo{\Pi\seq\Lambda,C_1}
                                    \hypo{\ldots}
                                    \hypo{\Pi\seq\Lambda,C_n}
                                    \infer3{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                            where each \(C_i\in\set{A_i, B_i}\).
                        \item\label{it:reduction tree lor left}
                            Let \(A_1\lor B_1,\ldots,A_n\lor B_n\in\Pi\) with
                            \(\lor\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\lor\):left}
                                    \label{eq:reduction:lor:left}
                                    \hypo{C_1,\Pi\seq\Lambda}
                                    \hypo{\ldots}
                                    \hypo{C_n,\Pi\seq\Lambda}
                                    \infer3{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                            where each \(C_i\in\set{A_i, B_i}\).
                        \item\label{it:reduction tree lor right}
                            Let \(A_1\lor B_1,\ldots,A_n\lor B_n\in\Lambda\) with \(\lor\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\lor\):right}
                                    \label{eq:reduction:lor:right}
                                    \hypo{\Pi\seq\Lambda,A_1, B_1,\ldots,A_n, B_n}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree limplies left}
                            Let \(A_1\limplies B_1,\ldots,A_n\limplies B_n\in\Pi\) with
                            \(\limplies\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\limplies\):left}
                                    \label{eq:reduction:limplies:left}
                                    \hypo{B_1,\Pi\seq\Lambda,A_1}
                                    \hypo{\ldots}
                                    \hypo{B_n,\Pi\seq\Lambda, A_n}
                                    \infer3{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree limplies right}
                            Let \(A_1\limplies B_1,\ldots,A_n\limplies B_n\in\Lambda\) with
                            \(\limplies\) as the outermost logical symbol.
                            Then the following push operation can be performed:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\limplies\):right}
                                    \label{eq:reduction:limplies:right}
                                    \hypo{A_1,\ldots,A_n,\Pi\seq\Lambda, B_1, \ldots, B_n}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree forall left}
                            Let \(\forall x_1A_1(x_1),\ldots,\forall x_nA_n(x_n)\in\Pi\)
                            with \(\forall\) as the outermost logical symbol,
                            and let \(a_i\) be an independent variable that has not been used in
                            reductions of \(\forall x_iA_i(x_i) : i \in\set{1,\ldots,n}\)
                            at this branch height.
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\forall\):left}
                                    \label{eq:reduction:forall:left}
                                    \hypo{A_1(a_1),\ldots,A_n(a_n),\Pi\seq\Lambda}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree forall right}
                            Let \(\forall x_1A_1(x_1),\ldots,\forall x_nA_n(x_n)\in\Lambda\)
                            with \(\forall\) as the outermost logical symbol,
                            and let \(a_1,\ldots,a_n\) be the first \(n\) independent
                            variables not available at this branch height.
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\forall\):right}
                                    \label{eq:reduction:forall:right}
                                    \hypo{\Pi\seq\Lambda,A_1(a_1),\ldots,A_n(a_n)}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree exists left}
                            Let \(\exists x_1A_1(x_1),\ldots,\exists x_nA_n(x_n)\in\Pi\)
                            with \(\exists\) as the outermost logical symbol,
                            and let \(a_1,\ldots,a_n\) be the first \(n\) independent
                            variables not available at this branch height.
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\exists\):left}
                                    \label{eq:reduction:exists:left}
                                    \hypo{A_1(a_1),\ldots,A_n(a_n),\Pi\seq\Lambda}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree exists right}
                            Let \(\exists x_1A_1(x_1),\ldots,\exists x_nA_n(x_n)\in\Lambda\)
                            with \(\exists\) as the outermost logical symbol,
                            and let \(a_i\) be the first independent variable that has not
                            been used in reductions of
                            \(\exists x_iA_i(x_i) : i \in\set{1,\ldots,n}\)
                            at this branch height.
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:\(\exists\):right}
                                    \label{eq:reduction:exists:right}
                                    \hypo{\Pi\seq\Lambda,A_1(a_1),\ldots,A_n(a_n)}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                        \item\label{it:reduction tree else}
                            If \(\Pi\) and \(\Lambda\) have \emph{any} formulae in common,
                            push the \emph{halting symbol} \halt{} onto the branch:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:halt}
                                    \label{eq:reduction:halt}
                                    \hypo{\halt}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                            If the sequences \(\Pi\) and \(\Lambda\) have \emph{nothing}
                            in common, perform the following push operation:
                            \begin{equation}
                                \begin{prooftree}
                                    \tag{reduction:else}
                                    \label{eq:reduction:else}
                                    \hypo{\Pi\seq\Lambda}
                                    \infer1{\Pi\seq\Lambda}
                                \end{prooftree}
                            \end{equation}
                    \end{enumerate}
            \end{enumerate}
            If there are unhandled leaves still left in this iteration loop,
            continue iterating over the unhandled leaves, else jump
            to~\ref{it:reduction tree loop}.
    \end{enumerate}
\end{definition}

Note that in the construction of a reduction tree,
the case~\eqref{eq:reduction:else} provides a possibility
for the formation of an infinite loop. If this happens and
some branch simply keeps growing indefinitely,
as new sequents \(\Pi\seq\Lambda\) keep getting pushed on top of it,
the sequent \(\Gamma\seq\Delta\) at the root of the tree
is not provable.

\begin{example}\label{exa:reduction tree}
    We construct a reduction tree for the sequent
    \(A\limplies B\seq\lnot A\lor B\).
    \begin{equation*}
        \begin{prooftree}
            \hypo{\halt}
            \infer1{B, A\limplies B\seq\lnot A\lor B, \lnot A, B}
            \hypo{\halt}
            \infer1{A, A\limplies B\seq\lnot A\lor B, \lnot A, B, A}
            \infer1[\eqref{eq:reduction:lnot:right}]{A\limplies B\seq\lnot A\lor B, \lnot A, B, A}
            \infer2[\eqref{eq:reduction:limplies:left}]{A\limplies B\seq\lnot A\lor B, \lnot A, B}
            \infer1[\eqref{eq:reduction:lor:right}]{A\limplies B\seq\lnot A\lor B}
        \end{prooftree}
    \end{equation*}
    As both of the branches of the tree halt,
    the sequent is provable.
\end{example}

\begin{exercise}[8.3.1]\label{exe:8.3.1}
    Construct a reduction tree for the sequent
    \(\lnot\exists xF(x)\seq \forall y\lnot F(y)\) in \LK{}.
\end{exercise}

\begin{exercise}[8.3.2]\label{exe:8.3.2}
    Construct a reduction tree for the sequent
    \(\exists x\arcs{A(x)\limplies B(x)}\seq \forall xA(x)\limplies\exists xB(x)\) in \LK{}.
\end{exercise}

\begin{example}[Infinite reduction tree]\label{exa:infinite reduction tree}
    Let us observe the sequent \(\forall x\exists yA(x,y)\seq\) and its reduction tree:
\begin{equation*}
    \begin{prooftree}
        \hypo{\infty}
        \ellipsis{\eqref{eq:reduction:else}}{A(a,b),\exists yA(a,y),\forall x\exists yA(x,y)\seq}
        \infer1[\eqref{eq:reduction:else}]{A(a,b),\exists yA(a,y),\forall x\exists yA(x,y)\seq}
        \infer1[\eqref{eq:reduction:else}]{A(a,b),\exists yA(a,y),\forall x\exists yA(x,y)\seq}
        \infer1[\eqref{eq:reduction:exists:left}]{\exists yA(a,y), \forall x\exists yA(x,y)\seq}
        \infer1[\eqref{eq:reduction:forall:left}]{\forall x\exists yA(x,y)\seq}
    \end{prooftree}
\end{equation*}
Therefore the contradiction at the root of the tree cannot be proven.
\end{example}

Equipped with this new tool, we may now show that validity implies provability.

\begin{theorem}[Validity implies provability]\label{the:validity implies provability}
    If a formula \(A\) is valid, then it is provable.
\end{theorem}

\begin{proof}
    Let \(\Gamma\seq\Delta\) be an \emph{unprovable} sequent in \LK{}.
    We construct an interpretation \(\interp=\tuple{\tuple{D,\phi},\phi_0}\),
    which does \emph{not} satisfy \(\Gamma\seq\Delta\).

    By the first assumption, there is an infinite branch in
    the reduction tree \(T\arcs{\Gamma\seq\Delta}\).
    If \(\Gamma_i,\Delta_i\in T\arcs{\Gamma\seq\Delta}\) and we define
    \begin{equation*}
        \cup\Gamma = \set{A \mid A\in\Gamma_i}
        \quad\text{and}\quad
        \cup\Delta = \set{B \mid B\in\Delta_i}
        \,,
    \end{equation*}
    then there can be no predicate constants \(R\arcs{\ldots}\) nor
    free independent variables \(a_i\), so that
    \begin{equation*}
        R\arcs{a_1,\ldots,a_n}\in \cup\Gamma\cap\cup\Delta,
    \end{equation*}
    as the sets \(\cup\Gamma\) and \(\cup\Delta\) are separate.

    For simplicity, we assume that there are no individual
    function constants \(f\) in our language \(L\), so the only
    free individual variables \(a\) are the only terms of \(L\).
    We can then define our interpretation
    \(\interp=\tuple{\tuple{D,\phi},\phi_0}\) as follows:
    we let \(D = \set{a_0,a_1,\ldots}\) and define the relation
    \begin{equation*}
        \phi = \left\{
            \begin{aligned}
                &\arcs{a_1,\ldots,a_n}\in\phi(R) \iff R(a_1,\ldots,a_n)\in\cup\Gamma, \\
                &\phi(a) = \phi_0(a) = a \\
                &\phi(x) = \phi_0(x) = x \\
            \end{aligned}
        \right.\,.
    \end{equation*}
    Notice that if \(\arcs{a_1,\ldots,a_n}\in\phi(R)\),
    then \( R(a_1,\ldots,a_n)\notin\cup\Delta\).
    Also, if \(R(a_1,\ldots,a_n)\in\cup\Delta\),
    then \( R(a_1,\ldots,a_n)\notin\cup\Gamma\) and
    \(\arcs{a_1,\ldots,a_n}\notin\phi(R)\).

    We now induce on the number of logical symbols \(n\) in a formula \(A\),
    and show that the intrepretation \(\interp\) defined above
    satisfies all formulae in \(\cup\Gamma\),
    but none in \(\cup\Delta\). In the base case \(n=0\),
    so \(A\) is a predicate constant \(R\). By definition,
    any predicate constant \(R\arcs{a_1,\ldots,a_n}\) is
    in \(\cup\Gamma\) and satisfied by \(\interp\),
    whereas any \(R\arcs{a_1,\ldots,a_n}\in\cup\Delta\)
    is not satisfied. The claim then holds for \(n=0\).

    We then make the inductive hypothesis \IH{} that the interpretation
    \(\interp\) satisfies all logical formulae \(A\in\cup\Gamma\) with \(n\leq k\)
    logical symbols, whereas it does not satisfy any formulae \(B\in\cup\Delta\)
    with the same constraint on \(n\). In the inductive step,
    we once again add one logical symbol at a time, and show
    that satisfiability is preserved.

    If \(A = \lnot C\in\cup\Gamma\), then it appears in \(\Gamma_i\)
    during some build step \(i\), and will remain there from then on.
    However, it will never appear on the right in \(\cup\lambda\),
    because by definition, the reduction tree would then \halt{},
    which contradicts our assumptions.
    We now produce the formula \(C\in\cup\Delta\)
    by applying \eqref{eq:reduction:lnot:left}.
    According to \IH{}, \(\interp\) does not satisfy \(C\in\cup\Delta\),
    meaning \(\lnot C\in\cup\Gamma\) is satisfied.
    The case where \(A = \lnot C\in\cup\Delta\)
    is entirely symmetric to this proof, so induction is closed
    on the symbol \(\lnot\).

    Now let \(A = C\land D\in\cup\Gamma\). This again means that
    after some build step \(i\) the formula \(C\land D\) appears
    in the reduction tree, and we can apply \eqref{eq:reduction:land:left}
    to produce the sequence \(C,D\).
    Now according to the \IH{}, the individual formulae \(C\)
    and \(D\) are satisfied by \(\interp\), meaning that
    \(C\land D\) is satisfied by definition.

    If \(A = C\land D\in\cup\Delta\), it will appear on the right
    side of the reduction tree after some build step \(i\),
    and we can use \eqref{eq:reduction:land:right} to produce \(C\) and \(D\).
    According to \IH{}, \(\interp\) satisfies neither \(C\) nor \(D\).
    Again, this leads to \(C\land D\in\cup\Delta\) \emph{not} being satisfied
    by definition, closing the induction on the symbol \(\land\).

    \begin{exercise}[8.3.3]\label{exe:8.3.3}
        Show that the inductive step maintains
        the satisfiability in  the interpretation \(\interp\)
        for the symbol \(\lor\).
    \end{exercise}

    If \(A = C\limplies D\in\cup\Delta\), then by the inductive hypothesis
    \(\interp\) does not satisfy \(D\), but satisfies \(C\).
    Therefore \(C\limplies D\) is not satisfied in \(\interp\).
    A more complex case is when \(A = C\limplies D\in\cup\Gamma\),
    as \eqref{eq:reduction:limplies:left} causes a split in the reduction tree:
    \begin{enumerate}
        \item
            If the tree does not \halt{} on the right,
            then \(C\in\cup\Delta\) is not satisfied in \(\interp\),
            and \(C\limplies D\in\cup\Gamma\) must be satisfied.
        \item
            If the tree does not \halt{} on the left,
            then \(D\in\cup\Gamma\) is satisfied and \(C\limplies D\in\cup\Gamma\)
            must be satisfied by definition.
    \end{enumerate}
    This closes the induction on the symbol \(\limplies\).

    Assuming that \(A = \forall xC(x)\in\cup\Gamma\),
    at some point we may apply \eqref{eq:reduction:forall:left}
    to produce \(C(a)\in\cup\Gamma\). By the inductive hypothesis,
    \(C(a)\) is satisfied by \(\interp\) for any assignment \(\phi_0\),
    and therefore \(\forall xC(x)\in\cup\Gamma\) is satisfied in
    \(\interp\) by definition.

    To save page space, the rest of the cases are omitted,
    as they are \emph{very} similar and based
    entirely on the definitions. This closes the induction.
\end{proof}

Together with theorem~\ref{the:provability implies validity},
theorem~\ref{the:validity implies provability}
shows that \LK{} is complete.

\section{Predicate calculus with equality}

This is also known as the ''Theory of Equality'' and is denoted with \(\LK_=\).
Here we add one additional symbol \(=\) to the alphabet of \LK{},
and use it to form a set of binary predicates with the following set
of axioms concerning the terms \(s\), \(s_i\), \(t_i\),
function symbols \(f\) and predicate symbols \(R\).
\begin{axiom}[Axioms of equality]\label{axi:equality}
\begin{align}
\tag{=:ax:1}\label{eq:ax:1}
    &\seq s = s, \\
\tag{=:ax:2}\label{eq:ax:2}
    s_1 = t_1,\ldots,s_n = t_n &\seq f(s_1,\ldots,s_n) = f(t_1,\ldots,t_n) \\
\tag{=:ax:3}\label{eq:ax:3}
    s_1 = t_1,\ldots,s_n = t_n &\seq R(s_1,\ldots,s_n)\seq R(s_1,\ldots,s_n)
\end{align}
\end{axiom}
The statements~\eqref{eq:ax:1}--\eqref{eq:ax:3} form the equality axioms.

\begin{proposition}[7.2]\label{prop:7.2}
    If \(A(a_1,\ldots,a_n)\) is a formula,
    then the substitution formula
    \begin{equation}\tag{substitution}\label{eq:substitution}
        s_1 = t_1,\ldots,s_n=t_n,A(s_1,\ldots,s_n)\seq A(t_1,\ldots,t_n)
    \end{equation}
    is \LK-provable. In particular:
    \begin{align}
        \tag{=:symmetry}\label{eq:symmetry}
            s=t&\seq t=s\,,\\
        \tag{=:transitivity}\label{eq:transitivity}
            s=t,t=v&\seq s=v\quad\text{and} \\
        \tag{=:sequential symmetry}\label{eq:sequential symmetry}
            s_1 = t_1,\ldots,s_n = t_n&\seq t_1 = s_1, \ldots, t_n = s_n\,.
    \end{align}
\end{proposition}

\begin{proof}
    We start with~\eqref{eq:symmetry}.
    According to the axioms~\eqref{eq:ax:1} and \eqref{eq:ax:3},
    we may write
    \begin{equation*}
        \begin{prooftree}
            \hypo{\eqref{eq:ax:1}}
            \ellipsis{}{\seq s=s}
            \hypo{s_1 = t_1, s_2 = t_2, R(s_1,s_2) \seq R(t_1,t_2)}
            \infer1[\eqref{eq:ax:3}]{s=t, s=s, s=s\seq t=s}
            \infer[double]1[\eqref{eq:exchange:left}]{s=s, s=s, s=t \seq t=s}
            \infer1[\eqref{eq:contraction:left}]{s=s, s=t \seq t=s}
            \infer2[\eqref{eq:cut}]{s = t\seq t = s}
        \end{prooftree}
    \end{equation*}
    As for~\eqref{eq:transitivity}, the proof
    \begin{equation*}
        \begin{prooftree}
            \hypo{\eqref{eq:symmetry}}
            \ellipsis{}{s = t\seq t = s}
            \hypo{\eqref{eq:ax:1}}
            \ellipsis{}{\seq t = t}
            \hypo{s_1 = t_1, s_2 = t_2, R(s_1,s_2) \seq R(t_1,t_2)}
            \infer1[\eqref{eq:ax:3}]{t=s, t=t ,t=v\seq s=v}
            \infer[double]1[\eqref{eq:exchange:left}]{t=t, t=s, t=v \seq s=v}
            \infer2[\eqref{eq:cut}]{t=s, s=v\seq s=v}
            \infer2[\eqref{eq:cut}]{s = t, t = v\seq s = v}
        \end{prooftree}
    \end{equation*}
    should suffice.

    Proving \eqref{eq:sequential symmetry} is very simple:
    it is a special case of the following proof of
    \eqref{eq:substitution}, with \(n=1\), and will therefore
    be left as an optional exercise.

    To prove the general case of \eqref{eq:substitution},
    we induce on the number of logical symbols \(n\) in \(A\).
    In the base case, \(n = 0\) and \(A\) is a predicate constant \(R\).
    The claim then holds by axiom \eqref{eq:ax:3}.
    For the inductive hypothesis \IH{}, we assume that the claim holds
    for \(n\leq k\) symbols in \(A\). We then add the known logical symbols
    to \(A\) one at a time to close the induction.

    If \(A = \lnot B\), denote \(\bar s = s_1,\ldots,s_n\) and
    \(\bar t = t_1,\ldots,t_n\). Then
    \begin{equation*}
        \begin{prooftree}
            \hypo{\eqref{eq:symmetry}}
            \ellipsis{}{s_2 = t_2 \seq t_2 = s_2}
            \hypo{\eqref{eq:symmetry}}
            \ellipsis{}{s_1=t_1\seq t_1=s_1}
            \hypo{\IH}
            \ellipsis{}{t_1=s_1,\ldots,t_n=s_n,A(\bar t)\seq A(\bar s)}
            \infer1[\eqref{eq:lnot:left}]{\lnot A(\bar s), t_1=s_1,\ldots,t_n=s_n,A(\bar t)\seq}
            \infer[double]1[\eqref{eq:exchange:left}]{A(\bar t), t_1=s_1,\ldots,t_n=s_n,\lnot A(\bar s)\seq}
            \infer1[\eqref{eq:lnot:right}]{t_1=s_1,\ldots,t_n=s_n,\lnot A(\bar s)\seq \lnot A(\bar t)}
            \infer2[\eqref{eq:cut}]{s_1=t_1,t_2=s_2,\ldots,t_2=s_2,\lnot A(\bar s)\seq \lnot A(\bar t)}
            \infer2[\eqref{eq:cut}]{}
            \ellipsis{nÃ\eqref{eq:cut} and \eqref{eq:exchange:left}}{}
            \infer1{s_1 = t_1, \ldots,s_n=t_n, \lnot A(\bar s) \seq \lnot A(\bar t)}
        \end{prooftree}
    \end{equation*}
    If \(A = B\land C\), we proceed as follows:
    \small
    \begin{equation*}
        \begin{prooftree}
            \hypo{\IH}
            \ellipsis{}{s_1 = t_1, \ldots,s_n=t_n, B(\bar s) \seq B(\bar t)}
            \infer1{n\times\eqref{eq:exchange:left}~\&~\eqref{eq:land:left}~\&~n\times\eqref{eq:exchange:left}}
            \infer1{s_1 = t_1, \ldots,s_n=t_n, B(\bar s)\land C(\bar s) \seq B(\bar t)}
            \hypo{\IH}
            \ellipsis{}{s_1 = t_1, \ldots,s_n=t_n, C(\bar s) \seq C(\bar t)}
            \infer1{n\times\eqref{eq:exchange:left}~\&~\eqref{eq:land:left}~\&~n\times\eqref{eq:exchange:left}}
            \infer1{s_1 = t_1, \ldots,s_n=t_n, B(\bar s)\land C(\bar s) \seq C(\bar t)}
            \infer2[\eqref{eq:land:right}]{s_1 = t_1, \ldots,s_n=t_n, B(\bar s)\land C(\bar s) \seq B(\bar t)\land C(\bar t)}
        \end{prooftree}
    \end{equation*}
    \normalsize
    The case \(A = B\lor C\) goes almost identically, and is left as an optional exercise.

For the case \(A = B\limplies C\) we denote the sequence of equalities
\(s_1=t_1,\ldots,s_n=t_n\) with \(S\simeq T\). We can then argue as follows:

    \begin{equation*}
        \begin{prooftree}
            \hypo{\eqref{eq:sequential symmetry}}
            \ellipsis{}{S\simeq{}T\seq T\simeq S}
            \hypo{\IH}
            \ellipsis{}{S\simeq T, B(\bar t)\seq B(\bar s)}
            \infer2[\(n\times\)\eqref{eq:cut}]{S\simeq T,B(\bar t)\seq B(\bar s)}
            \hypo{\IH}
            \ellipsis{}{S\simeq T,C(\bar s)\seq C(\bar t)}
            \infer[double]1[\eqref{eq:exchange:left}]{C(\bar s), S\simeq{}T\seq C(\bar t)}
            \infer2[\eqref{eq:limplies:left}]{B(\bar s)\limplies C(\bar s), B(\bar t),S\simeq{}T\seq C(\bar t)}
            \infer[double]1[\eqref{eq:exchange:left}]{B(\bar t),S\simeq T, B(\bar s)\limplies C(\bar s)\seq C(\bar t)}
            \infer1[\eqref{eq:limplies:right}]{S\simeq T, B(\bar s)\limplies C(\bar s)\seq B(\bar t)\limplies C(\bar t)}
        \end{prooftree}
    \end{equation*}

    In the case of \(A = \forall xB(x)\),
    the additional symbol is actually an additional
    independent variable \(a\). Hence we can argue as follows:
    \begin{equation*}
        \begin{prooftree}
            \hypo{\IH}
            \ellipsis{}{S\simeq T,B(a,\bar s)\seq B(a,\bar t)}
            \infer[double]1[\eqref{eq:exchange:left}]{B(a,\bar s),S\simeq{}T\seq B(a,\bar t)}
            \infer1[\eqref{eq:forall:left}]{\forall xB(x,\bar s),S\simeq{}T\seq B(a,\bar t)}
            \infer1[\eqref{eq:forall:right}]{\forall xB(x,\bar s),S\simeq{}T\seq\forall xB(x,\bar t)}
            \infer[double]1[\eqref{eq:exchange:left}]{S\simeq T, \forall xB(x,\bar s)\seq\forall xB(x,\bar t)}
        \end{prooftree}
    \end{equation*}
    The case where \(A = \exists xB(x)\) is very similar to the case \(A = \forall xB(x)\),
    and will therefore be left as an extra exercise,h closes the induction.
\end{proof}

\begin{definition}[Essential formula]\label{def:essential formula}
    If the eliminated formula  in the application of \eqref{eq:cut}
    is \(s=t\), the cut is called \emph{unessential}.
    Otherwise the formula is \emph{essential}.
\end{definition}

\begin{theorem}[\eqref{eq:cut}-elimination in \(\LK_=\)]%
    \label{the:cut-elimination in LK=}
    If a sequent \(\Gamma\seq\Delta\) is provable in \(\LK_=\) with an essential
    \eqref{eq:cut}, then it is also provable without an essential \eqref{eq:cut}.
\end{theorem}

\begin{proof}
    \begin{exercise}[7.6]\label{exe:7.6}
        Left as an exercise. This is very similar to the general
        Gentzens Hauptsatz, with only two additional subcases:
        either \eqref{eq:cut}--\eqref{eq:mix} concerns an equality
        axiom or it is obtained by weakening.
    \end{exercise}
\end{proof}

\section{Peano arithmetic or PA}

This is also called ''The Theory of natural numbers''.
This is a special case of the general language of \LK{},
where we restrict our alphabet and terms according to the following
definitions. We use the notation \LN{} to refer to this language.

\begin{definition}[Alphabet of \PA{}]\label{def:alphabet of peano arithmetic}
    We have the following symbols at our disposal,
    when talking in the language of Peano Arithmetic \PA:
    \begin{itemize}
        \item
            There is only one individual constant \(\bar0\),
            known in our meta language as ''zero''.
        \item
            The only three function constants are the unary left-associative
            \emph{successor} \('\), and the binary operations
            \emph{addition} \(+\) and \emph{product} \(\times\).
        \item
            The only binary predicate symbol is \(=\),
            the equality defined in the previous chapter.
    \end{itemize}
\end{definition}

\begin{definition}[Numerals]\label{def:numerals}
    In order to simplify our notations,
    we make the following bijective notational agreement:
    \begin{equation*}
        \bar0\mapsto\bar0,\quad
        \bar1\mapsto\bar0',\quad
        \bar2\mapsto\bar0'',\quad
        \bar3\mapsto\bar0''',\quad
        \ldots\quad,\quad
        \bar{n}\mapsto\bar0^{\overbrace{\prime\cdots\prime}^{n\text{ times}}}\,.
    \end{equation*}
    In other words, \(\bar{n}\) refers to the natural number \(n\in\Nset\),
    familiar to us from our meta language.
\end{definition}

\begin{definition}[Terms of \PA{}]\label{def:terms of peano arithmetic}
    We define the words or \emph{terms} of \PA{} recursively as follows:
    \begin{enumerate}
        \item
            Free variables and \(\bar0\) are terms.
        \item
            If \(s\) and \(t\) are terms, then so are \(s'\),
            \(s+t\) and \(s\times t\).
    \end{enumerate}
\end{definition}
\begin{definition}[Closed terms of \PA{}]\label{def:closed terms of peano arithmetic}
    \emph{Closed terms} are composed of the numerals of definition~\ref{def:numerals}
    and the function constants and equality of definition~\ref{def:alphabet of peano arithmetic}:
    \begin{enumerate}
        \item
            Individual numerals are closed terms.
        \item
            If \(\bar m\) and \(\bar n\) are closed terms,
            then \(\bar m '\), \(\bar m +\bar n\), \(\bar m\times\bar n\)
            and \(\bar m = \bar n\) are closed terms as well.
    \end{enumerate}
\end{definition}

Note that a statement like \(\bar2+\bar3=\bar5\) is something that needs to be
proven in this language. We may not take it for granted. To be able to prove
things in \PA{}, we must first agree on our axioms, which are listed below.

\begin{axiom}[Logical axioms of \PA{}]\label{axi:logical axioms of PA}
    There is only a single logical axiom: if \(A\) is a formula,
    then \(A\seq A\) is this axiom.
\end{axiom}
\begin{axiom}[Equality axioms of \PA{}]\label{axi:equality axioms of PA}
    The equality axioms of \PA{} are special instances of the axioms
    of \LK=. These are
    \begin{align}
        \tag{\LN:eq:ax:1}\label{LN:eq:ax:1}
        &\seq s=s \\
        \tag{\LN:eq:ax:2}\label{LN:eq:ax:2}
        s = t &\seq s'=t', \\
        \tag{\LN:eq:ax:3}\label{LN:eq:ax:3}
        s_1=t_1, s_2=t_2 &\seq s_1+s_2 =t_1+t_2,
        \quad\text{and} \\
        \tag{\LN:eq:ax:4}\label{LN:eq:ax:4}
        s_1=t_1, s_2=t_2 &\seq s_1\times s_2 =t_1\times t_2,
    \end{align}
\end{axiom}
\begin{axiom}[Mathematical axioms of \PA{}]\label{axi:mathematical axioms of PA}
    \begin{align}
        \tag{\LN:m:ax:1}\label{LN:m:ax:1}
        s'=t'&\seq s=t, \\
        \tag{\LN:m:ax:2}\label{LN:m:ax:2}
        s' = 0 &\seq, \\
        \tag{\LN:m:ax:3}\label{LN:m:ax:3}
        &\seq s + \bar0 = s, \\
        \tag{\LN:m:ax:4}\label{LN:m:ax:4}
        &\seq s + t' = (s+t)', \\
        \tag{\LN:m:ax:5}\label{LN:m:ax:5}
        &\seq s\times\bar0 = \bar0,
        \quad\text{and} \\
        \tag{\LN:m:ax:6}\label{LN:m:ax:6}
        &\seq s\times t' = s \times t + s\,.
    \end{align}
\end{axiom}

Finally, the inductive principle can also be formalized.
We will not be needing the formalization in this course,
but it is shown here for completeness.

\begin{axiom}[Inductive axiom]\label{axi:inductive axiom}
    Induction is formalized as follows:
    let \(\bar k\) and \(\bar n\) be closed terms. Then
    \begin{equation}\tag{induction}\label{induction}
        P(\bar0), P(\bar k)\limplies P(\bar k') \seq \forall\bar nP(\bar n)\,.
    \end{equation}
\end{axiom}

\paragraph{Note:}
Before we dive in further and start proving things,
please remember that \(n\in\Nset\) is a natural number
in our meta language, whereas the \emph{numerals} or
\emph{closed terms} \(\bar n\) are the representations of
these numbers in our \emph{object language}.

\paragraph{Note 2:}
The allowed inference rules are the ones given in
definition~\ref{def:inference rules in LK}.

\begin{exercise}[PA.1]\label{exe_PA.1}
    Prove that \(\bar2 + \bar1 = \bar3\).
\end{exercise}

It can be shown more generally, that if \(\bar m\) and \(\bar n\)
are numerals, then
\begin{equation*}
    \seq\bar m + \bar n = \overline{m + n}
    \quad\text{and}\quad
    \seq\bar m \times \bar n = \overline{m \times n}\,.
\end{equation*}

\begin{proposition}[9.4]\label{prop:9.4}
    \PA{} is consistent, as in the empty sequent \(\seq\)
    is not provable in it.
\end{proposition}

\begin{proof}
    Omitted. This is taken for granted.
\end{proof}

\begin{proposition}[9.6.1]\label{prop:9.6.1}
    For any closed term \(s\), there is a unique numeral \(\bar n\),
    so that the sequent \(\seq s = \bar n\) is provable.
\end{proposition}

\begin{proof}.
    Let \(k\) be the number of instances of the functions
    \('\), \(+\) and \(\times\) in \(s\). We induce on this \(k\).

    In the base case \(k=0\), we only have the single numeral \(\bar m\),
    for which the claim holds: axiomatically \(\seq s=s\), so \(\seq\bar m=\bar m\).
    For the inductive hypothesis, we assume that the claims \(\seq s=\bar m\)
    and \(\seq t=\bar n\) hold, each with \(k\leq p\) instances of the functions are provable.
    In the inductive step we add one more instance of the functions to the proofs
    and show that the cclaim still holds to close the induction.

    In the case of the successor \(\prime\),
    \begin{equation*}
        \begin{prooftree}
            \hypo{\seq s=\bar n}
            \hypo{s=\bar n \seq s'=\bar n'}
            \infer2[\eqref{eq:cut}]{\seq s'=\bar n'}
        \end{prooftree} \,.
    \end{equation*}
    Notice that \(\bar n'\) is \(\overline{n+1}\),
    means that \(\seq s'=\overline{n+1}\), which closes the induction on
    the successor \(\prime\).

    For the sum \(+\), we introduce axioms as needed:
    \scriptsize
    \begin{equation*}
        \begin{prooftree}
            \hypo{\seq \bar m+\bar n = \overline{m + n}}
            % --------------------------------
            \hypo{\seq t = \bar m}
            % --------------------------------
            \hypo{\seq s = \bar n}
            % --------------------------------
            \hypo{s = \bar n, t = \bar m \seq s + t = \bar m + \bar n}
            \infer2[\eqref{eq:cut}]{t = \bar m \seq s + t = \bar m + \bar n}
            \infer2[\eqref{eq:cut}]{\seq s+t = \bar m + \bar n}
            \hypo{s+t = \bar m + \bar n, \bar n + \bar m = \overline{n + m}\seq s+t = \overline{m + n}}
            % --------------------------------
            \infer2[\eqref{eq:cut}]{\bar m+\bar n = \overline{m + n}\seq s+t = \overline{m + n}}
            % --------------------------------
            \infer2[\eqref{eq:cut}]{\seq s+t=\overline{m + n}}
        \end{prooftree}
    \end{equation*}
    \normalsize
    The induction is then closed on the sum \(+\).
    To prove the case of the product \(\times\), simply replace \(+\)
    with \(\times\) in the above inductive step. This is left as an optional exercise,
    which closes the induction when completed.

    To prove the uniqueness of the numeral \(\bar n\),
    make the contrapositive assumption, so that
    there are differing numerals \(\bar p\) and \(\bar q\),
    so that by proposition~\ref{prop:7.2}
    \begin{equation*}
        \begin{prooftree}
            \hypo{\seq s = \bar p}
            % ------------------------
            \hypo{\seq s = \bar q}
            % ------------------------
            \hypo{s = \bar q\seq \bar q = s}
            % ------------------------
            \hypo{\bar q = s, s = \bar p\seq \bar q = \bar p}
            \infer2[\eqref{eq:cut}]{s = \bar q, s = \bar p\seq \bar q = \bar p}
            \infer2[\eqref{eq:cut}]{s = \bar p\seq \bar q = \bar p}
            \infer2{\seq \bar q = \bar p}
        \end{prooftree} \,.
    \end{equation*}
    Thus supposing that the numerals differ in the given manner
    leads to them being the same numeral. We are then done with
    the proof.
\end{proof}

\begin{proposition}[9.6.2]\label{prop:9.6.2}
    In \PA{}, if \(s\) and \(t\) are closed terms, then either
    the sequent \(\seq s=t\) or \(s=t\seq\) holds. The terms
    are either equal, or they are not.
\end{proposition}

\begin{proof}
    As we have already proved proposition \ref{prop:9.6.1},
    it is enough to show that if \(\bar m\) and \(\bar n\) are
    numerals, then either \(\seq \bar m = \bar n\) or \(\bar m = \bar n\seq\) holds.
    In other words, either the two numerals are equal, or they are not.
    We induce on the number \(k\) of successors \(\prime\) in the numerals.

    In the base case \(k=0\), so the numerals are both zeroes,
    and \(\seq\bar0=\bar0\) holds according to the axioms of \PA{}.
    The claim then holds for \(k=0\).

    In the inductive hypothesis, we assume that the claim \(\seq\bar m=\bar n\)
    holds for \(k = p\) successors in the numerals \(\bar m\) and \(n\).
    We then add one more successor to either \(\bar m\) or \(\bar n\)
    and demonstrate that the claim still holds after the mattter.

    By the axioms of \PA{} and inductive hypotheses,
    \begin{equation*}
        \begin{prooftree}
            \hypo{\seq\bar m=\bar n}
            \hypo{m = n\seq\bar m'=\bar n'}
            \infer2[\eqref{eq:cut}]{\seq\bar m'=\bar n'}
        \end{prooftree}\,,
    \end{equation*}
    so if \(m\) and \(n\) are the same natural numbers,
    then \(\seq\bar m=\bar n\).

    Now, as by the axioms of \PA{}, zero cannot be the successor
    of any numeral, as in
    \begin{equation*}
        \bar1'=0\seq,\quad
        \bar2'=0\seq,\quad
        \bar3'=0\seq,\quad
        \ldots\,,
    \end{equation*}
    and the axioms also allow us to make the proof
    \begin{equation*}
        \begin{prooftree}
            \hypo{\bar n''=\bar 0'\seq \bar n' = \bar0}
            \hypo{\bar n'=0\seq}
            \infer2{\bar n''=\bar 0'\seq}
        \end{prooftree}\,,
    \end{equation*}
    we know that
    \begin{equation*}
        \bar2'=\bar1\seq,\quad
        \bar3'=\bar1\seq,\quad
        \bar4'=\bar1\seq,\quad
        \ldots\,.
    \end{equation*}
    Similarly, but in a more concrete and examplary manner,
    we can argue that
    \begin{equation*}
        \begin{prooftree}
            \hypo{3 = 2 \seq 2 = 1}
            \hypo{2 = 1 \seq}
            \infer2{3\seq 2\seq}
        \end{prooftree}\,,
    \end{equation*}
    where the numeral \(\bar3\) may be replaced with any numeral \(\bar n\), so
    \begin{equation*}
        \bar3'=\bar2\seq,\quad
        \bar4'=\bar2\seq,\quad
        \bar5'=\bar2\seq,\quad
        \ldots\,.
    \end{equation*}

    Proceeding in the above manner ad infinitum,
    we can produce all sequences \(\bar m=\bar n\seq\),
    for the natural numbers \(m\) and \(n\), for which \(m > n\) holds.
    To handle the case where \(m < n\), simply exchange the roles
    of \(m\) and \(n\) in the proofs, which produces \(\bar n=\bar m\seq\).

    We have now shown that, speaking in metalanguage,
    either \(m=n\), \(m>n\) or \(m < n\) holds,
    but none at the same time. Therefore
    \begin{equation*}
        \bar m = \bar n\seq,\quad
        \seq\bar m=\bar n,
        \quad\text{or}\quad
        \bar n=\bar m\,.
    \end{equation*}
    It now remains to show that \(\bar m=\bar n\seq\),
    if and only if \(\bar n=\bar m\seq\), which we omit.
\end{proof}

\section{The incompleteness of Peano arithmetic}

We now get to the actual meat of the course.
We wish to show that Peano arithmetic \PA{}
fulfills the following definition.

\begin{definition}[Incompleteness of a logical system]\label{def:incompleteness}
    An axiom system \(S\) is \emph{incomplete},
    if it does not contain proofs for
    \(\seq A\) nor \(\seq\lnot A\) for some sentence \(A\).
\end{definition}

In fact, we wish to show that any system \(S\) that contains
Peano arithmetic (is its superset) ends up being incomplete because of it.
To do this, we need several different definitions and results.
The first one of these, \emph{primitive recursive functions},
works on the metalanguage level.

\begin{definition}[Primitive recursive functions]\label{def:PRF}
    Primitive recursive functions or \PRF{s} is the smallest
    class of functions \(f\) generated by the following function
    skeletons or schemata:
    \begin{align}
        \tag{PRF:successor}\label{prf:successor}
        f(x) &= x', \\
        \intertext{where \(\prime\) is the successor function,}
        \tag{PRF:constant}\label{prf:constant}
        f(x_1,\ldots,x_n) &= k,\quad n\geq 1,\quad k\in\Nset, \\
        \tag{PRF:projection}\label{prf:projection}
        f(x_1,\ldots,x_n) &= x_i,\quad i\in\set{1,\ldots,n} \\
        \tag{PRF:compound}\label{prf:compound}
        f(x_1,\ldots,x_n) &= g\arcs[\big]{
            h_1(x_1.\ldots,x_n),\ldots,h_m(x_1.\ldots,x_n)
        } \intertext{where \(g\) and \(h_1\)..\(h_m\) are \PRF{s},}
        \tag{PRF:simple recursion}\label{prf:simple recursive}
        f(0) &= k,\quad f(x') = g(x, f(x))
        \intertext{where \(k\in\Nset\) and \(g\) is a \PRF, and finally}
        \tag{PRF:compound recursion}\label{prf:compound recursive}
        f(0, x_2,\ldots,x_n) &=g(x_2,\ldots,x_n),\\
        \nonumber
        f(x', x_2,\ldots,x_n) &= h\arcs[\big]{x,f(x_2,\ldots,x_n),x_2,\ldots,x_n},
    \end{align}
    where \(g\) and \(h\) are \PRF{}s.
\end{definition}

The fact that \PRF{s} work on the metalanguage level means that
they are actual functions in the usual sense, not just function symbols.
The \PRF{}s of definition \ref{def:PRF} are used to build other functions recursively,
and they function as the base cases of this process.
There is also a concept strongly related to \PRF{s},
\emph{primitive recursive relations}, that we must discuss.

\begin{definition}[Primitive recursive relation]\label{def:primitive recursive relation}
    A relation \(R\) of length \(n\) is said to be \emph{primitive recursive},
    if there is a characteristic \PRF{} \(f: X\to\set{0,1}\),
    and \(f(a_1,\ldots,a_n) = 0\), if and only if
    \(R(a_1,\ldots,a_n)\) is true or \((a_1,\ldots,a_n)\in R\).
\end{definition}

\begin{example}[I]\label{exa:PRF successor}
    By definition, the successor function \('\) is
    a \PRF{}: \(0'=1, 1'=2, 2'=3,\ldots,n'=n+1,\ldots\).
\end{example}

\begin{example}[II]\label{exa:PRF sum}
    The addition of natural numbers is
    of type \eqref{prf:compound recursive}:
    \begin{itemize}
        \item \(f(0,n) = p_2(0,n) = n\), where \(p_2\)
            is a \PRF{} of type \eqref{prf:projection}.
        \item
            Set \(h = k\circ p_2\) and
            \(k\circ p_2(m,f(m,n,n)) = k(f(m,n)) = f(m,n)'\).
            Notice that \(h\) is of type \eqref{prf:compound}
            and \(k\) of type \eqref{prf:successor}.
    \end{itemize}
    Now set \(f(m',n) = h(m, f(m,n),n) = f(m,n)'\).
    Then \(m+n = f(m,n)\).
\end{example}

For further clarification of example \ref{exa:PRF sum}, consider
\begin{align*}
    f(5,9) &= h(4,f(4,9),9) = f(4,9)' = 14, \\
    f(4,9) &= h(3,f(3,9),9) = f(3,9)' = 13, \\
    f(3,9) &= h(2,f(2,9),9) = f(2,9)' = 12, \\
    f(2,9) &= h(1,f(1,9),9) = f(1,9)' = 11, \\
    f(1,9) &= h(0,f(0,9),9) = f(0,9)' = 10 \,.
\end{align*}

\begin{example}[III]\label{exa:PRF constant}
    Constant functions \(v_0(n)\equiv 0\),
    \(v_1(n)\equiv 1\), \(v_2(n)\equiv 2\) and so forth
    are of type \eqref{prf:constant}.
\end{example}

\begin{exercise}[10.2.1]\label{exe:10.2.1}
    Show that multiplication of natural numbers \(\times\)
    is a primitive recursive function.
\end{exercise}

\begin{example}[V]\label{exa:PRF predecessor}
    Predecessor or \emph{VorgÃ¤nger} functions
    are of type \eqref{prf:simple recursive}:
    \begin{enumerate}
        \item First define \(\PRED(0) = v_0(0) = 0\),
            where \(v_0\) is of type \eqref{prf:constant}.
        \item Then set \(\PRED(n') = p_1(n,\PRED(n)) = n\),
            where \(p_1\) is of type \eqref{prf:projection}.
    \end{enumerate}
    In other words,
    \begin{equation*}
        \PRED(n) =
        \left\{
            \begin{aligned}
                0&, \quad n=0\\
                n-1&,\quad n>0
            \end{aligned}
        \right.\,.
    \end{equation*}
\end{example}

\begin{example}[VI]\label{exa:PRF sign}
    The \emph{signum} function is of type \eqref{prf:simple recursive}:
    \begin{enumerate}
        \item First define \(\SIGN(0) = v_0(0)  = 0\),
            where \(v_0\) is of type \eqref{prf:constant}.
        \item Then set \[\SIGN(n') = v_1\circ p_2(n,\SIGN(n))
            = v_1(p_2(n,\SIGN(n))) = v_1(\SIGN(n)) = 1\,.\]
            Note that \(v_1\) is of type \eqref{prf:constant},
            \(p_2\) of type \eqref{prf:projection}
            and \(v_1\circ p_2\) of type \eqref{prf:compound}.
    \end{enumerate}
\end{example}

A concrete example of the application of the signum function
is seen below:
\begin{align*}
    \SIGN(1) &= v_1(\SIGN(0)) = v_1(0) = 1 \\
    \SIGN(2) &= v_1(\SIGN(1)) = v_1(1) = 1 \\
             &\vdots \\
    \SIGN(n) &= 1, \quad n\in\Nset\setminus\set0\,.
\end{align*}

\begin{example}[VII]\label{exa:PRF permutation}
    Given a \PRF{} \(f(m,n)\), the \emph{permutation} of
    \(f\), \(\PERM(f(m,n)) = f(n,m)\), is of type
    \eqref{prf:compound recursive}. It can be constructed by setting
    \begin{equation*}
        \PERM(f(m,n)) = f(p_2(m,n), p_1(m,n)) = f(n,m)\,.
    \end{equation*}
    Here \(p_1\) and \(p_2\) are of type \eqref{prf:projection}.
\end{example}

\begin{example}[VIII]\label{exa:PRF cut of subtraction}
    A so calle \emph{cut of subtraction} \(CS\)
    is of type \eqref{prf:compound recursive}.
    It is generally defined as
    \begin{equation*}
        \CS(m,n) = \left\{
            \begin{aligned}
                0&,\quad m > n, \\
                n-m&,\quad m\leq n
            \end{aligned}\,.
        \right.
    \end{equation*}
    It is defined \emph{recursively} for \(m,n\in\Nset\) by setting
    \begin{align*}
        \CS(0,n)  &= p_1(n) = n\\
        \CS(m',n) &= \PRED(p_2(m,\CS(m,n),n)) = \PRED(\CS(m,n))\,,
    \end{align*}
    where \(p_1\) is of type \eqref{prf:projection} and \(\PRED\)
    of type \eqref{prf:compound recursive}.
\end{example}

An example of the application of cut of subtraction goes as follows:
\begin{align*}
    \CS(1,n)    &= \PRED(\CS(0,n)) = n-1 \\
    \CS(2,n)    &= \PRED(\CS(1,n)) = \PRED(n-1) = n-2 \\
                &\vdots \\
    \CS(n-1,n)  &= \PRED(n-(n-2)) = \PRED(2) = 1 \\
    \CS(n,n)  &= \PRED(n-(n-1)) = \PRED(1) = 0 \,.
\end{align*}
Finally, \(\CS(m,n) = 0\) for all \(m > n\).

\begin{example}[IX]\label{exa:PRF absolute difference}
    The \emph{absolute difference} \(\ADF\) function is
    of type \eqref{prf:compound}:
    \begin{equation*}
        \ADF(m,n) = \CS(m,n) + \CS(n,m) = \abs{m-n}\,.
    \end{equation*}
    Here \(\CS(m,n)\) is either \(n-m\) or \(0\),
    and \(\CS(n,m)\) either \(m-n\) or \(0\).
    As stated above, both \(\CS\) and \(+\)
    are \PRF{}s.
\end{example}

We now proceed to show that equality \(=\) is a primitive recursive
relation \(\PRR\) in \(\Nset^2\). Define the function \(f(m,n) = \SIGN(\ADF(m,n))\),
which is of type~\eqref{prf:compound} and
\begin{equation*}
    f(m,n) = \SIGN(\abs{m-n}) = \left\{
        \begin{aligned}
            0&,\quad m = n, \\
            1&,\quad m \neq n\,.
        \end{aligned}
    \right.
\end{equation*}
There then exists a (characteristic) \PRF{} for the relation \(=\),
whose values are in the set \(\set{0,1}\). Therefore the
relation \(=\) is a \PRR, as per definition~\ref{def:primitive recursive relation}.

\paragraph{Note:}
We say that \(m = n\) or \(m,n\in=\) (\(m\) and \(n\) are in an equality relation),
if and only if the above \PRF{} \(f(m,n) = 0\).
This is usually how equality is defined in computer algebra systems
such as \emph{Maxima}. This is then of immediate practical use as well!

\paragraph{Note 2:}
The relation \(<\) is also a \PRR{} in \(\Nset^2\):
\(m < n\), if and only if \(\CS(m,n) = 0\).

\subsection{General primitive recursive relations}

Assume \(R\) is a primitive recursive relation \PRR.
Now either the variables \(x_1,\ldots,x_n\)
are in \(R\), as in \(R(x_1,\ldots,x_n)\), or they are not.
Because \(R\) is a \PRR, there exists a characteristic function
of \(R\), \(f_R\), so that
\begin{equation*}
    f_R(x_1,\ldots,x_n) = \left\{
        \begin{aligned}
            0&,\quad (x_1,\ldots,x_n)\in R, \\
            1&,\quad (x_1,\ldots,x_n)\notin R\,.
        \end{aligned}
    \right.
\end{equation*}

\begin{lemma}(Consistency of \PA)\label{lem:10.5}
    Peano arithmetic \PA{} (and all of its supersets) are \emph{consistent},
    if and only if the sequent \(\seq\bar0=\bar1\)
    is \emph{not} provable in \PA. In other words,
    any formula \(A\) is provable, if \(\seq\bar0=\bar1\)
    is provable in \PA{}.
\end{lemma}

\begin{proof}
    Omitted.
\end{proof}

\begin{proposition}[10.6.1]\label{prop:10.6.1}
    Primitive recursive functions \PRF{} can be expressed
    in \LN{}, the language of \PA{}. More generally:

    \begin{tabenv}{Correspondence of \PRF{}s and \(\LN\).}
        \begin{tabular}{c|c|c}
            \toprule
            \(\Nset\) &Metalevel \(\Nset\) & \(\LN\) of \PA{}\\
            \midrule
            1. &Natural numbers \(n\in\Nset\)   & Numerals \(\bar n\in\LN\)\\
            2. &\PRF{s} \(f : \Nset^n\to\Nset\)   & \(n\)-ary function symbols \(\bar f\) \\
            3. &\PRR{s} \(R\subseteq \Nset^n\)  & \(n\)-ary atomic formulae or predicates \(\bar R\)\\
            \bottomrule
        \end{tabular}
    \end{tabenv}
\end{proposition}

\begin{proof}[A sketch of the proof]
\item[1.] This should be clear by declaration.

\item[2.]
    In the set \(\Nset\), primitive recursive functions can be expressed
    in terms of the successor \('\), addition \(+\) and multiplication \(\times\).
    These correspond to the function symbols \(\bar'\), \(\bar+\) and \(\bar\times\)
    in \(\LN\). In particular,
    \begin{equation*}
        f(m_1,\ldots,m_n)   = p\in\Nset,
        \quad\text{if and only if}\quad
        \bar f(m_1,\ldots,m_n) = \bar p \in\LN\,.
    \end{equation*}
\item[3.]
    First notice that \(=\arcs{,\bar m}\) or \(=\bar m\)
    can be seen as a right-associative unary predicate symbol
    \(\bar R_{\bar m}\), and that \(\bar R_{\bar m}(t)\)
    is an atomic formula in \PA{}. Moreover, either
    \(\seq\bar R_{\bar m}(t)\) (\(\seq t=\bar m\)),
    or \(\bar R_{\bar m}(t)\seq\) (\(t=\bar m\seq\))
    is provable by proposition~\ref{prop:9.6.2},
    as \(t\) is a closed term.

    Then recall that \(m_1,\ldots,m_n\in\Nset\) either are in relation
    \(R\subseteq\Nset^n\), or they are not, if and only if \(R(m_1,\ldots,m_n)\)
    holds in \(\Nset^n\), if and only if
    \begin{equation*}
        f_R(m_1,\ldots,m_n) = \left\{
            \begin{aligned}
                0&,\quad m_1,\ldots,m_n \in R,\\
                1&,\quad m_1,\ldots,m_n\notin R\,,
            \end{aligned}
        \right.
    \end{equation*}
    where \(f_R\) is the characteristic function of \(R\), a \PRF{}.
    We then have the following: \(R(m_1,\ldots,m_n)\) holds in \(\Nset^n\),
    if and only if \(f_R(m_1,\ldots,m_n) = 0\), if and only if
    \begin{equation*}
        \seq f_R(m_1,\ldots,m_n) = 0
    \end{equation*}
    is provable in \(\PA\) and its supersets.

    We denote \(f_R(t_1,\ldots,t_n) = \bar0\) by a \emph{unary} predicate
    \(R_\delta(t_1,\ldots,t_n)\). Then either \(\seq R_\delta(t_1,\ldots,t_n)\)
    is provable is \PA{}, or it is not. In particular,
    \(\seq R_\delta(m_1,\ldots,m_n)\) in \PA{}.
\end{proof}

The converse of proposition~\ref{prop:10.6.1} also holds.
This we prove as follows.

\begin{proof}
    By lemma \ref{lem:10.5} the consistency of \PA{}
    can be expressed by saying that \(\seq\bar1=\bar0\) is not provable in \PA{}.
    If the sequent \(\seq\bar R(\bar m_1,\ldots,\bar m_n)\)
    is provable in \PA{}, then the relation \(R(m_1,\ldots,m_n)\)
    holds in \(\Nset^n\), as in \(m_1,\ldots,m_n\in R\).
    We make the contrapositive assumption that \(m_1,\ldots,m_n\notin R\).

    Now the characteristic function \(f_R(m_1,\ldots,m_n) = 1\),
    which when expressed in \PA{} means that
    \(\bar f_R(\bar m_1,\ldots,\bar m_n) = \bar1\),
    or simply \(\bar f_R = \bar1\).
    Since \(\seq\bar R(\bar m_1,\ldots,\bar m_n)\) in \PA{},
    \(\seq\bar f_R =\bar0\) must be provable. Now
\begin{equation*}
    \begin{prooftree}
        \hypo{\seq\bar f_R=\bar1}
        \hypo{\bar f_R=\bar1\seq\bar1=\bar f_R}
        \infer2[\eqref{eq:cut}]{\seq\bar1=\bar f_R}
    \end{prooftree}
\end{equation*}
and therefore
\begin{equation*}
    \begin{prooftree}
        \hypo{\seq\bar f_R=\bar0}
        \hypo{\seq\bar1=\bar f_R}
        \hypo{\bar1=\bar f, \bar f=\bar0\seq\bar1=\bar0}
        \infer2[\eqref{eq:cut}]{\bar f=\bar0\seq\bar1=\bar0}
        \infer2[\eqref{eq:cut}]{\seq\bar1=\bar0}
    \end{prooftree}
\end{equation*}
This makes \PA{} inconsistent, meaning \(R(m_1,\ldots,m_n)\) holds in \(\Nset^n\).
\end{proof}

\subsection{GÃ¶del numbering}

Recall the prime number factorization of natural numbers:
any natural number \(n\geq 2\) can be expressed \emph{uniquely}
as the finite product of primes:
\begin{equation*}
    n = 2^{p_1}\times 3^{p_2}\times 5^{p_3}\times\cdots\times p^{p_m},
\end{equation*}
where the numbers \(2\), \(3\), \(5\), \ldots, \(p\) are the first \(m\)
prime numbers and \(p_1,p_2,p_3,\ldots,p_m \in\Nset\), with \(p_m\neq 0\).
For example,
\begin{alignat*}{4}
    &2 = 2^1,           &&\quad3 = 2^0\times3^1,                 &&\quad4 = 2^2, &&\quad5 = 2^0\times 3^0\times 5^1, \\
    &6 = 2^1\times 3^1, &&\quad7= 2^0\times3^0\times5^0\times7^1,&&\quad8 = 2^3, &&\quad9 = 2^0\times3^2,\ldots
\end{alignat*}
We now make the following definition based on this knowledge.

\begin{definition}[GÃ¶del numbering]\label{def:gÃ¶del numbering}
    The formulae of \PA{} are composed of a finite set of symbols
    \(\set{x,y,\limplies,\land,\lor\lnot,\exists,\ldots,\forall}\),
    so they can be enumerated as follows:

    \begin{tabenv}{An enumeration of symbols in \PA{}}
        \label{tab:an enumeration of symbols in PA}
        \begin{tabular}[]{c|C|C|C|C|C|C|C|C|C|C|C|C|C}
            \toprule
            \(\Nset\) & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10  & 11 & \cdots & n\\
            \midrule
            Symbol  & = & \bar0 & \exists & x & \prime & ( & ) & + & \seq & ,  & -- & \cdots & \forall\\
            \bottomrule
        \end{tabular}
    \end{tabenv}

    Based on this enumeration, \emph{which is not unique},
    we can write the sentence ''\(\bar0\) has a successor'',
    expressed in \PA{} as \(A:\exists x(x=0')\), as the sequence
    \(34641257\), based on table~\ref{tab:an enumeration of symbols in PA}.
    The unique (in enumeration~\ref{tab:an enumeration of symbols in PA})
    \emph{GÃ¶del number} of \(A\), \(G(A)\), is then
    \begin{equation*}
        G(A) = \G A = 2^3\times3^4\times5^6\times7^4\times11^1\times13^2\times17^5\times19^7 \,.
    \end{equation*}
\end{definition}

In a given enumeration, each formula \(A\in\LN\) has a unique GÃ¶del number \(\G A\).
On the other hand, given a natural number \(n\in\Nset\), we could in principle
find its prime factorization and hence discover, whether \(n\) is the
GÃ¶del number of \(A\) for some formula \(A\).
For example
\begin{equation*}
    6 = 2^1\times 3^1\,,
\end{equation*}
meaning it corresponds to the string \(==\) in
the enumeration~\ref{tab:an enumeration of symbols in PA}
However, for most \(n\) this is not in any way practical,
because of technical limitations.

\begin{exercise}[GÃ¶del 1]\label{exe:gÃ¶del 1}
    What is the GÃ¶del number \(\G A\) for the formula
    \(A: \exists x(x+\bar0 = x)\)? Is the number \(4\,261\,409\,460\)
    the GÃ¶del number of some formula?
\end{exercise}

Next we define the process of constructing GÃ¶del numbers for
sequences of formulae, such as \(\Gamma: A_1,A_2,A_3,\ldots,A_n\).
Here we simply write
\begin{equation*}
    G(\Gamma) = \G\Gamma =
    2^{\G{A_1}}\times3^{\G{A_2}}\times5^{\G{A_3}}\times\cdots\times p^{\G{A_n}} \,.
\end{equation*}
In other words, the prime numbers from \(2\) to \(p\),
where \(p\) is the \(n\)th prime number,
are raised to the GÃ¶del numbers of the individual formulae \(A_i\),
to produce the GÃ¶del number for the sequence \(\Gamma\).

Sequents \(\Gamma\seq\Delta\), inferences \(Q\) of definition~\ref{def:inference}
and proofs \(P\) of definition~\ref{def:proof in LK} can also be given
their own unique GÃ¶del numbers \(\G{\Gamma\seq\Delta}\),
\(\G Q\) and \(\G P\), by converting them to suitable strings of symbols
and applying the procedure above. For example, for the proofs
\begin{equation*}
    P_1:
    \begin{prooftree}
        \hypo{\Gamma\seq\Delta}
        \infer1{S}
    \end{prooftree}
    \quad\text{and}\quad
    P_2:
    \begin{prooftree}
        \hypo{Q_1}
        \hypo{Q_2}
        \infer2{S}
    \end{prooftree}
\end{equation*}
the GÃ¶del numbers are
\[
\G{P_1} = 2^{\G\Gamma}\times3^{\G\seq}\times5^{\G\Delta}\times7^{\G-}\times11^{\G S}
\] and
\[\G{P_2} = 2^{\G Q_1}\times3^{\G Q_2}\times5^{\G-}\times7^{\G S}\]
respectively. Note that \(\seq\) and \(-\) are the symbols for the sequent arrow
and inference line, again respectively.

\paragraph{Note:}
The GÃ¶del number \(\G{\bar n} \neq n\).
For example, \(\bar3 = \bar0'''\)
and therefore in the enumeration of table~\ref{tab:an enumeration of symbols in PA},
\(\G{\bar3} = 2^2\times3^5\times5^5\times7^5\neq3\).

\subsection{Arithmetization of Peano Arithmetic}

We have now given a procedure for \emph{arithmetizing} formulae,
sequences of formulae, sequents and proofs. We now make this more
formal via the following definition.

\begin{definition}[Arithmetization]\label{def:arithmetization}
    If an object, action or operation \(\Phi\) has a GÃ¶del number \(\G\Phi\),
    then it has a unique \emph{arithmetization} which is equal to that number.
\end{definition}

In other words, all objects can be given a counterpart in the set
of natural numbers \(\Nset\). For example, if \(\Phi\) is a predicate
\(\bar R(\bar x_1,\ldots,\bar x_n)\) in \PA{},
the sequent \(\seq\bar R(\bar x_1,\ldots,\bar x_n)\) is provable in \PA{},
\emph{and} there is a \PRR{} \(R\subseteq \Nset^n\)
such that \(R(\G{\bar x_1},\ldots,\G{\bar x_n})\)
holds in \(\Nset^n\), then \(R\) is the arithmetization of \(\bar R\).

Another example of an arithmetization goes as follows:
let \(\Phi\) be an operation applied to objects
\(\bar x_1,\ldots,\bar x_n \in\PA\),
so that the resulting object \(\bar y\in\PA{}\).
If there is a \PRF{} \(f\) in \(\Nset\) so that
\(f(\G{\bar x_1},\ldots,\G{\bar x_n},)) = \G{\bar y}\),
then \(f\) is the arithmetization of \(\Phi\).

Notice that the converse is also true:
if \(a_1,\ldots,a_n,b\in\Nset\) happen to be
GÃ¶del numbers, so that
\begin{equation*}
    a_1 = \G{\bar x_1},\ldots, a_n = \G{\bar x_n}, b = \G{\bar y}\,,
\end{equation*}
then there are unique corresponding numerals of definition~\ref{def:numerals},
\begin{equation*}
    \num{\G{\num x_1}},\ldots,\num{\G{\num x_n}} \in\PA\,.
\end{equation*}
If there also exists a mapping
\(f(\G{\num x_1},\ldots,\G{\num x_n}) = \G{\num y} \in\Nset\),
then there exists an operation \(\Phi\), that performs the mapping
\(\arcs{\num{\G{\num x_1}},\ldots,\num{\G{\num x_n}}}\mapsto\num{\G{\num y}}\in\PA{}\).

\paragraph{Note:}
This converse relation is rather complex, and is not proven
in the book of Takeuti. We therefore also skip the proof. {\Large\trollface}

\begin{lemma}[10.8.1]\label{lem:10.8.1}
    The rule~\eqref{eq:substitution} can be arithmetized:
    if \(\num x(a_0)\) is a fully indicated expression of \PA,
    and \(\num x(\num y)\) is obtained from \(\num x(a_0)\)
    by substituting all instances of \(a_0\) with \(\num y\)
    in \(\num x\), then there is a unique \PRF{} \(\sub: \Nset^2\to\Nset\),
    such that
    \begin{equation*}
        \sub\arcs*{\G{\num y}, \G{\num x(a_0)}} = \num{\G{\num x(\num y)}}\,,
    \end{equation*}
    and there is a unique function symbol \(\num{\sub{}}\) in \PA{},
    such that \(\seq\sub\arcs*{\G{\num y}, \G{\num x(a_0)}} = \num{\G{\num x(\num y)}}\)
    is provable in \PA{}.
\end{lemma}




\subsection{Tarski's theorem}

\subsection{GÃ¶del's incompleteness theorems}

{\raggedright%
\printbibliography[heading=bibintoc]%
}

\end{document}

